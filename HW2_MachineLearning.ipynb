{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2_MachineLearning",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WesleyAldridge/HW2_MachineLearning/blob/master/HW2_MachineLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rt44vyY1xW9b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## HW2 - Convolutional Neural Network For CIFAR10 Data Set"
      ]
    },
    {
      "metadata": {
        "id": "Pfuun9431eEs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Instructions from professor:\n",
        "\n",
        "\"The goal of this homework is to create a convolutional neural network for the CIFAR10 data set.\n",
        "\n",
        "You should not use any pretrained convnets that come with Keras. You have to create and train your own convnets with Keras from scratch.\n",
        "\n",
        "Make sure that the data is divided into:\n",
        "\n",
        "- training set (80%)\n",
        "- validation set (20%)\n",
        "- test set.\n",
        "\n",
        "Use the training set to train your neural networks. Evaluate their performance on the validation data set.\n",
        "\n",
        "After trying several different architectures, choose the one that performs best on the validation set. Try at least four different architectures by using data augmentation, using dropout, varying the number of layers, the number of filters, etc.\n",
        "\n",
        "Train this final architecture on the data from the training set and validation set and evaluate its performance on the test set.\n",
        "\n",
        "Reevaluate your best architecture using k-fold validation with k=5, that is, the size of the validation fold is 20%. Does the accuracy/loss obtain by k-fold validation differ from the accuracy/loss obtain by simple hold-out validation."
      ]
    },
    {
      "metadata": {
        "id": "l34GNy7tyNks",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loading the CIFAR10 data set"
      ]
    },
    {
      "metadata": {
        "id": "qICX25UpB4W0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**train_images.shape = (50000, 32, 32, 3)**\n",
        "\n",
        "**test_images.shape  = (10000, 32, 32, 3) **\n",
        "\n",
        "50,000 train_images of shape 32x32 pixels, made up of 3 channels (R,G,B)\n",
        "\n",
        "10,000 test_images of shape 32x32 pixels, made up of 3 channels (R,G,B)"
      ]
    },
    {
      "metadata": {
        "id": "FSJyddqGexl5",
        "colab_type": "code",
        "outputId": "4127f6f5-f26b-4293-c359-114de40a8564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as mpl\n",
        "from math import ceil\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)\n",
        "\n",
        "train_images.shape, test_images[0][0][0]#.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 14s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3),\n",
              " array([0.61960787, 0.4392157 , 0.19215687], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "NqoZq8yYBBvp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Making Basic CNN, Architecture 1"
      ]
    },
    {
      "metadata": {
        "id": "wLs7MsrVKae1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Example CNN from class notes:\n",
        "\n",
        "Input Images > Conv2d (ReLU) > MaxPool > Conv2d (ReLU) > MaxPool > Fully Connected > Fully Connected (output) \n",
        "\n",
        "This is two convolution modules (convolution(ReLU) + pooling) for feature extraction, and two fully connected layers for classification."
      ]
    },
    {
      "metadata": {
        "id": "8ES8_yvjAVfP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_basic = Sequential()\n",
        "\n",
        "# \"To start, the CNN receives an input feature map: a 3-dimensional matrix, where\n",
        "# the size of the first two dimensions corresponds to the length and width of the\n",
        "# images in pixels, and the size of the third dimension is 3 (corresponding to the\n",
        "# 3 channels of a color image: red, green, and blue).\" - class notes\n",
        "\n",
        "# \"A convolution extracts tiles of the input feature map, and applies filters to them\n",
        "# to compute new features, producing an output feature map, or convolved feature\n",
        "# (which may have a different size and depth than the input feature map)\n",
        "# Convolutions are defined by two parameters:\n",
        "# Size of the tiles that are extracted (typically 3x3 or 5x5 pixels).\n",
        "# The depth of the output feature map, which corresponds to the number of filters\n",
        "# that are applied.\" - class notes\n",
        "\n",
        "# \"After each convolution operation, the CNN applies a Rectified Linear Unit (ReLU)\n",
        "# transformation to the convolved feature, in order to introduce nonlinearity into\n",
        "# the model\" - class notes\n",
        "CNN_basic.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "\n",
        "# \"After ReLU comes a pooling step, in which the CNN downsamples the convolved feature\n",
        "# (to save on processing time), reducing the number of dimensions of the feature map,\n",
        "# while still preserving the most critical feature information.\" - class notes\n",
        "\n",
        "# \"size of the max-pooling filter is typically 2x2 pixels\" - from class notes\n",
        "# the class notes talk about using a stride of 2, so I will use that here as well:\n",
        "CNN_basic.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "CNN_basic.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "CNN_basic.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2) )\n",
        "\n",
        "CNN_basic.add(layers.Flatten())\n",
        "CNN_basic.add(layers.Dense(512, activation='relu'))\n",
        "# \"Typically, the final fully-connected layer contains a softmax activation function,\n",
        "# which outputs a probability value from 0 to 1 for each of the classification labels\n",
        "# the model is trying to predict\" - class notes\n",
        "CNN_basic.add(layers.Dense(10, activation='softmax')) \n",
        "#CNN.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2MGYWy7wXZZi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluating on validation set:"
      ]
    },
    {
      "metadata": {
        "id": "U3wmUq8ESbjn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1730
        },
        "outputId": "73a97487-aab4-4e5f-8c1f-09cc1f83927b"
      },
      "cell_type": "code",
      "source": [
        "rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)  # default values: RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
        "CNN_basic.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "CNN_basic.fit(x=train_images, y=train_labels, batch_size=32, epochs=20, verbose=1, validation_split=0.2, shuffle=True)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "40000/40000 [==============================] - 13s 332us/step - loss: 1.4596 - acc: 0.4780 - val_loss: 1.1781 - val_acc: 0.5881\n",
            "Epoch 2/50\n",
            "40000/40000 [==============================] - 12s 304us/step - loss: 1.0576 - acc: 0.6318 - val_loss: 1.1722 - val_acc: 0.5885\n",
            "Epoch 3/50\n",
            "40000/40000 [==============================] - 12s 303us/step - loss: 0.8764 - acc: 0.6974 - val_loss: 0.9738 - val_acc: 0.6701\n",
            "Epoch 4/50\n",
            "40000/40000 [==============================] - 12s 303us/step - loss: 0.7327 - acc: 0.7479 - val_loss: 0.9638 - val_acc: 0.6833\n",
            "Epoch 5/50\n",
            "40000/40000 [==============================] - 12s 303us/step - loss: 0.6029 - acc: 0.7935 - val_loss: 0.9288 - val_acc: 0.7055\n",
            "Epoch 6/50\n",
            "40000/40000 [==============================] - 12s 299us/step - loss: 0.4953 - acc: 0.8307 - val_loss: 1.0302 - val_acc: 0.7002\n",
            "Epoch 7/50\n",
            "40000/40000 [==============================] - 12s 298us/step - loss: 0.4097 - acc: 0.8619 - val_loss: 1.1078 - val_acc: 0.6832\n",
            "Epoch 8/50\n",
            "40000/40000 [==============================] - 12s 299us/step - loss: 0.3408 - acc: 0.8883 - val_loss: 1.1880 - val_acc: 0.7088\n",
            "Epoch 9/50\n",
            "40000/40000 [==============================] - 12s 303us/step - loss: 0.2849 - acc: 0.9061 - val_loss: 1.3052 - val_acc: 0.7041\n",
            "Epoch 10/50\n",
            "40000/40000 [==============================] - 12s 299us/step - loss: 0.2486 - acc: 0.9186 - val_loss: 1.3576 - val_acc: 0.7013\n",
            "Epoch 11/50\n",
            "40000/40000 [==============================] - 12s 297us/step - loss: 0.2306 - acc: 0.9257 - val_loss: 1.6424 - val_acc: 0.7026\n",
            "Epoch 12/50\n",
            "40000/40000 [==============================] - 12s 296us/step - loss: 0.2128 - acc: 0.9329 - val_loss: 1.6275 - val_acc: 0.6975\n",
            "Epoch 13/50\n",
            "40000/40000 [==============================] - 12s 297us/step - loss: 0.2036 - acc: 0.9359 - val_loss: 2.0961 - val_acc: 0.6798\n",
            "Epoch 14/50\n",
            "40000/40000 [==============================] - 12s 297us/step - loss: 0.1903 - acc: 0.9415 - val_loss: 2.0611 - val_acc: 0.7022\n",
            "Epoch 15/50\n",
            "40000/40000 [==============================] - 12s 298us/step - loss: 0.1763 - acc: 0.9455 - val_loss: 1.7745 - val_acc: 0.6779\n",
            "Epoch 16/50\n",
            "40000/40000 [==============================] - 12s 301us/step - loss: 0.1732 - acc: 0.9478 - val_loss: 2.1944 - val_acc: 0.6752\n",
            "Epoch 17/50\n",
            "40000/40000 [==============================] - 12s 294us/step - loss: 0.1775 - acc: 0.9474 - val_loss: 2.0223 - val_acc: 0.6958\n",
            "Epoch 18/50\n",
            "40000/40000 [==============================] - 12s 292us/step - loss: 0.1756 - acc: 0.9489 - val_loss: 2.1969 - val_acc: 0.7032\n",
            "Epoch 19/50\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 0.1721 - acc: 0.9496 - val_loss: 2.5664 - val_acc: 0.6709\n",
            "Epoch 20/50\n",
            "40000/40000 [==============================] - 12s 294us/step - loss: 0.1722 - acc: 0.9516 - val_loss: 2.3857 - val_acc: 0.6915\n",
            "Epoch 21/50\n",
            "40000/40000 [==============================] - 12s 294us/step - loss: 0.1695 - acc: 0.9523 - val_loss: 2.2081 - val_acc: 0.6844\n",
            "Epoch 22/50\n",
            "40000/40000 [==============================] - 12s 292us/step - loss: 0.1622 - acc: 0.9541 - val_loss: 2.2680 - val_acc: 0.6878\n",
            "Epoch 23/50\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 0.1523 - acc: 0.9564 - val_loss: 2.4055 - val_acc: 0.7022\n",
            "Epoch 24/50\n",
            "40000/40000 [==============================] - 12s 294us/step - loss: 0.1565 - acc: 0.9587 - val_loss: 2.6232 - val_acc: 0.7011\n",
            "Epoch 25/50\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 0.1636 - acc: 0.9576 - val_loss: 2.6966 - val_acc: 0.6976\n",
            "Epoch 26/50\n",
            "40000/40000 [==============================] - 12s 294us/step - loss: 0.1590 - acc: 0.9595 - val_loss: 2.5702 - val_acc: 0.7040\n",
            "Epoch 27/50\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.1533 - acc: 0.9601 - val_loss: 2.3557 - val_acc: 0.6822\n",
            "Epoch 28/50\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 0.1509 - acc: 0.9619 - val_loss: 2.7608 - val_acc: 0.6820\n",
            "Epoch 29/50\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.1648 - acc: 0.9602 - val_loss: 2.7709 - val_acc: 0.6747\n",
            "Epoch 30/50\n",
            "40000/40000 [==============================] - 12s 292us/step - loss: 0.1469 - acc: 0.9631 - val_loss: 2.7224 - val_acc: 0.6943\n",
            "Epoch 31/50\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 0.1568 - acc: 0.9632 - val_loss: 3.0544 - val_acc: 0.6835\n",
            "Epoch 32/50\n",
            "40000/40000 [==============================] - 12s 294us/step - loss: 0.1567 - acc: 0.9632 - val_loss: 3.2671 - val_acc: 0.6761\n",
            "Epoch 33/50\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 0.1563 - acc: 0.9627 - val_loss: 2.7960 - val_acc: 0.6769\n",
            "Epoch 34/50\n",
            "40000/40000 [==============================] - 12s 294us/step - loss: 0.1454 - acc: 0.9660 - val_loss: 3.1521 - val_acc: 0.6604\n",
            "Epoch 35/50\n",
            "40000/40000 [==============================] - 12s 298us/step - loss: 0.1476 - acc: 0.9663 - val_loss: 2.8692 - val_acc: 0.6962\n",
            "Epoch 36/50\n",
            "40000/40000 [==============================] - 12s 298us/step - loss: 0.1591 - acc: 0.9649 - val_loss: 2.8632 - val_acc: 0.6806\n",
            "Epoch 37/50\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.1427 - acc: 0.9677 - val_loss: 3.4456 - val_acc: 0.6894\n",
            "Epoch 38/50\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.1483 - acc: 0.9659 - val_loss: 3.1225 - val_acc: 0.6864\n",
            "Epoch 39/50\n",
            "40000/40000 [==============================] - 11s 286us/step - loss: 0.1521 - acc: 0.9679 - val_loss: 3.4851 - val_acc: 0.6644\n",
            "Epoch 40/50\n",
            "40000/40000 [==============================] - 11s 287us/step - loss: 0.1453 - acc: 0.9692 - val_loss: 3.0099 - val_acc: 0.6742\n",
            "Epoch 41/50\n",
            "40000/40000 [==============================] - 11s 285us/step - loss: 0.1418 - acc: 0.9699 - val_loss: 3.0019 - val_acc: 0.6855\n",
            "Epoch 42/50\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.1535 - acc: 0.9684 - val_loss: 3.2797 - val_acc: 0.6877\n",
            "Epoch 43/50\n",
            "40000/40000 [==============================] - 11s 285us/step - loss: 0.1440 - acc: 0.9701 - val_loss: 3.2443 - val_acc: 0.6896\n",
            "Epoch 44/50\n",
            "40000/40000 [==============================] - 11s 283us/step - loss: 0.1529 - acc: 0.9696 - val_loss: 3.1894 - val_acc: 0.6798\n",
            "Epoch 45/50\n",
            "40000/40000 [==============================] - 11s 283us/step - loss: 0.1519 - acc: 0.9700 - val_loss: 3.0973 - val_acc: 0.6912\n",
            "Epoch 46/50\n",
            "40000/40000 [==============================] - 11s 283us/step - loss: 0.1545 - acc: 0.9705 - val_loss: 3.3632 - val_acc: 0.7028\n",
            "Epoch 47/50\n",
            "40000/40000 [==============================] - 11s 286us/step - loss: 0.1456 - acc: 0.9708 - val_loss: 3.2992 - val_acc: 0.6893\n",
            "Epoch 48/50\n",
            "40000/40000 [==============================] - 11s 285us/step - loss: 0.1476 - acc: 0.9709 - val_loss: 3.1075 - val_acc: 0.6654\n",
            "Epoch 49/50\n",
            "40000/40000 [==============================] - 11s 285us/step - loss: 0.1495 - acc: 0.9717 - val_loss: 3.5682 - val_acc: 0.6971\n",
            "Epoch 50/50\n",
            "40000/40000 [==============================] - 11s 282us/step - loss: 0.1538 - acc: 0.9728 - val_loss: 3.2552 - val_acc: 0.6918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f753f334630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "-bwnsRTwRcaZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There is overfitting: the accuracy is much higher (97%) on the training data than on the validation data (69%)."
      ]
    },
    {
      "metadata": {
        "id": "rIifYKRSradN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Network with Dropout added, Architecture 2"
      ]
    },
    {
      "metadata": {
        "id": "pjBpyvX-rAyJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_dropout = Sequential()\n",
        "\n",
        "CNN_dropout.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "\n",
        "CNN_dropout.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "CNN_dropout.add(Dropout(1 - .9))\n",
        "\n",
        "CNN_dropout.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "CNN_dropout.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2) )\n",
        "CNN_dropout.add(Dropout(1 - .9))\n",
        "\n",
        "CNN_dropout.add(layers.Flatten())\n",
        "CNN_dropout.add(layers.Dense(512, activation='relu'))\n",
        "CNN_dropout.add(Dropout(1 - .9))\n",
        "\n",
        "CNN_dropout.add(layers.Dense(10, activation='softmax')) \n",
        "#CNN.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WKtdJnTCrjOR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1730
        },
        "outputId": "a745ef55-3a13-45a7-d604-f135d62879e6"
      },
      "cell_type": "code",
      "source": [
        "rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)  # default values: RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
        "CNN_dropout.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "CNN_dropout.fit(x=train_images, y=train_labels, batch_size=32, epochs=20, verbose=2, validation_split=0.2, shuffle=True)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            " - 12s - loss: 1.4741 - acc: 0.4752 - val_loss: 1.1561 - val_acc: 0.5927\n",
            "Epoch 2/50\n",
            " - 11s - loss: 1.0974 - acc: 0.6166 - val_loss: 1.0064 - val_acc: 0.6481\n",
            "Epoch 3/50\n",
            " - 11s - loss: 0.9479 - acc: 0.6729 - val_loss: 0.9147 - val_acc: 0.6875\n",
            "Epoch 4/50\n",
            " - 11s - loss: 0.8412 - acc: 0.7107 - val_loss: 0.9151 - val_acc: 0.6948\n",
            "Epoch 5/50\n",
            " - 11s - loss: 0.7555 - acc: 0.7396 - val_loss: 0.9307 - val_acc: 0.7013\n",
            "Epoch 6/50\n",
            " - 11s - loss: 0.6920 - acc: 0.7681 - val_loss: 0.9372 - val_acc: 0.6861\n",
            "Epoch 7/50\n",
            " - 11s - loss: 0.6390 - acc: 0.7849 - val_loss: 0.9116 - val_acc: 0.7148\n",
            "Epoch 8/50\n",
            " - 11s - loss: 0.5982 - acc: 0.7997 - val_loss: 0.9397 - val_acc: 0.7080\n",
            "Epoch 9/50\n",
            " - 11s - loss: 0.5690 - acc: 0.8103 - val_loss: 0.8930 - val_acc: 0.7197\n",
            "Epoch 10/50\n",
            " - 11s - loss: 0.5454 - acc: 0.8187 - val_loss: 0.9343 - val_acc: 0.7060\n",
            "Epoch 11/50\n",
            " - 11s - loss: 0.5315 - acc: 0.8261 - val_loss: 0.9405 - val_acc: 0.7181\n",
            "Epoch 12/50\n",
            " - 11s - loss: 0.5229 - acc: 0.8325 - val_loss: 1.0526 - val_acc: 0.7228\n",
            "Epoch 13/50\n",
            " - 11s - loss: 0.5156 - acc: 0.8356 - val_loss: 1.0671 - val_acc: 0.6831\n",
            "Epoch 14/50\n",
            " - 11s - loss: 0.5059 - acc: 0.8391 - val_loss: 1.0930 - val_acc: 0.7222\n",
            "Epoch 15/50\n",
            " - 11s - loss: 0.4991 - acc: 0.8403 - val_loss: 1.3024 - val_acc: 0.7006\n",
            "Epoch 16/50\n",
            " - 11s - loss: 0.4982 - acc: 0.8421 - val_loss: 1.1418 - val_acc: 0.7077\n",
            "Epoch 17/50\n",
            " - 11s - loss: 0.5081 - acc: 0.8418 - val_loss: 1.1639 - val_acc: 0.7145\n",
            "Epoch 18/50\n",
            " - 11s - loss: 0.5039 - acc: 0.8452 - val_loss: 1.1553 - val_acc: 0.6695\n",
            "Epoch 19/50\n",
            " - 11s - loss: 0.5009 - acc: 0.8453 - val_loss: 1.2288 - val_acc: 0.7187\n",
            "Epoch 20/50\n",
            " - 11s - loss: 0.4982 - acc: 0.8468 - val_loss: 1.1429 - val_acc: 0.7190\n",
            "Epoch 21/50\n",
            " - 11s - loss: 0.5033 - acc: 0.8449 - val_loss: 1.0978 - val_acc: 0.6839\n",
            "Epoch 22/50\n",
            " - 11s - loss: 0.4969 - acc: 0.8481 - val_loss: 1.1031 - val_acc: 0.6979\n",
            "Epoch 23/50\n",
            " - 11s - loss: 0.5012 - acc: 0.8484 - val_loss: 1.3242 - val_acc: 0.7220\n",
            "Epoch 24/50\n",
            " - 11s - loss: 0.5008 - acc: 0.8479 - val_loss: 1.1180 - val_acc: 0.6974\n",
            "Epoch 25/50\n",
            " - 11s - loss: 0.5022 - acc: 0.8491 - val_loss: 1.1694 - val_acc: 0.7048\n",
            "Epoch 26/50\n",
            " - 11s - loss: 0.5128 - acc: 0.8483 - val_loss: 1.2578 - val_acc: 0.6770\n",
            "Epoch 27/50\n",
            " - 11s - loss: 0.4986 - acc: 0.8497 - val_loss: 1.2147 - val_acc: 0.7029\n",
            "Epoch 28/50\n",
            " - 11s - loss: 0.5069 - acc: 0.8479 - val_loss: 1.2612 - val_acc: 0.7028\n",
            "Epoch 29/50\n",
            " - 11s - loss: 0.5234 - acc: 0.8427 - val_loss: 1.1652 - val_acc: 0.7007\n",
            "Epoch 30/50\n",
            " - 11s - loss: 0.5315 - acc: 0.8443 - val_loss: 1.2051 - val_acc: 0.7020\n",
            "Epoch 31/50\n",
            " - 11s - loss: 0.5411 - acc: 0.8443 - val_loss: 1.2092 - val_acc: 0.6794\n",
            "Epoch 32/50\n",
            " - 11s - loss: 0.5435 - acc: 0.8422 - val_loss: 1.1700 - val_acc: 0.6862\n",
            "Epoch 33/50\n",
            " - 11s - loss: 0.5565 - acc: 0.8399 - val_loss: 1.3436 - val_acc: 0.6577\n",
            "Epoch 34/50\n",
            " - 11s - loss: 0.5494 - acc: 0.8383 - val_loss: 1.2644 - val_acc: 0.7055\n",
            "Epoch 35/50\n",
            " - 11s - loss: 0.5417 - acc: 0.8424 - val_loss: 1.2128 - val_acc: 0.6646\n",
            "Epoch 36/50\n",
            " - 11s - loss: 0.5624 - acc: 0.8358 - val_loss: 1.4267 - val_acc: 0.7010\n",
            "Epoch 37/50\n",
            " - 11s - loss: 0.5695 - acc: 0.8339 - val_loss: 1.3948 - val_acc: 0.7008\n",
            "Epoch 38/50\n",
            " - 11s - loss: 0.5691 - acc: 0.8362 - val_loss: 1.2525 - val_acc: 0.6988\n",
            "Epoch 39/50\n",
            " - 10s - loss: 0.5618 - acc: 0.8388 - val_loss: 1.3188 - val_acc: 0.6392\n",
            "Epoch 40/50\n",
            " - 11s - loss: 0.5664 - acc: 0.8381 - val_loss: 1.2390 - val_acc: 0.6836\n",
            "Epoch 41/50\n",
            " - 10s - loss: 0.5783 - acc: 0.8346 - val_loss: 1.2077 - val_acc: 0.6880\n",
            "Epoch 42/50\n",
            " - 11s - loss: 0.5822 - acc: 0.8341 - val_loss: 1.2079 - val_acc: 0.7075\n",
            "Epoch 43/50\n",
            " - 10s - loss: 0.5895 - acc: 0.8309 - val_loss: 1.3258 - val_acc: 0.6780\n",
            "Epoch 44/50\n",
            " - 10s - loss: 0.5927 - acc: 0.8349 - val_loss: 1.2485 - val_acc: 0.6669\n",
            "Epoch 45/50\n",
            " - 10s - loss: 0.5870 - acc: 0.8308 - val_loss: 1.3516 - val_acc: 0.7195\n",
            "Epoch 46/50\n",
            " - 10s - loss: 0.5899 - acc: 0.8303 - val_loss: 1.1825 - val_acc: 0.6607\n",
            "Epoch 47/50\n",
            " - 10s - loss: 0.6080 - acc: 0.8305 - val_loss: 1.3346 - val_acc: 0.6548\n",
            "Epoch 48/50\n",
            " - 10s - loss: 0.6094 - acc: 0.8250 - val_loss: 1.3667 - val_acc: 0.6598\n",
            "Epoch 49/50\n",
            " - 10s - loss: 0.6148 - acc: 0.8272 - val_loss: 1.3687 - val_acc: 0.6983\n",
            "Epoch 50/50\n",
            " - 10s - loss: 0.6123 - acc: 0.8272 - val_loss: 1.3354 - val_acc: 0.6592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f753f334b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "6jXfotVMRqWy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There is still overfitting. Acc (83%) is much higher than val_acc (66%). Acc worsened compared to the first architecture, and so did the val_acc. So maybe dropout isn't the solution?"
      ]
    },
    {
      "metadata": {
        "id": "etXoYMUvZu4N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Network with additional layers and more filters on each layer, Architecture 3"
      ]
    },
    {
      "metadata": {
        "id": "VvdSVWGeaOVK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_expanded = Sequential()\n",
        "\n",
        "CNN_expanded.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "CNN_expanded.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "CNN_expanded.add(Dropout(1 - 0.95))\n",
        "\n",
        "CNN_expanded.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "CNN_expanded.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2) )\n",
        "CNN_expanded.add(Dropout(1 - 0.95))\n",
        "\n",
        "CNN_expanded.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "CNN_expanded.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2) )\n",
        "CNN_expanded.add(Dropout(1 - 0.95))\n",
        "\n",
        "CNN_expanded.add(layers.Flatten())\n",
        "CNN_expanded.add(layers.Dense(512, activation='relu'))\n",
        "CNN_expanded.add(Dropout(1 - 0.95))\n",
        "\n",
        "CNN_expanded.add(layers.Dense(256, activation='relu'))\n",
        "CNN_expanded.add(Dropout(1 - 0.95))\n",
        "\n",
        "CNN_expanded.add(layers.Dense(128, activation='relu'))\n",
        "\n",
        "CNN_expanded.add(layers.Dense(10, activation='softmax')) \n",
        "#CNN.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ON6q6R8paaTi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "9c4dd0b3-31dd-4b3c-a8ba-f7481a701306"
      },
      "cell_type": "code",
      "source": [
        "rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)  # default values: RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
        "CNN_expanded.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "CNN_expanded.fit(x=train_images, y=train_labels, batch_size=32, epochs=20, verbose=2, validation_split=0.2, shuffle=True)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            " - 25s - loss: 1.6340 - acc: 0.4077 - val_loss: 1.2870 - val_acc: 0.5361\n",
            "Epoch 2/20\n",
            " - 23s - loss: 1.2158 - acc: 0.5747 - val_loss: 1.1573 - val_acc: 0.5919\n",
            "Epoch 3/20\n",
            " - 23s - loss: 1.0403 - acc: 0.6438 - val_loss: 0.9968 - val_acc: 0.6697\n",
            "Epoch 4/20\n",
            " - 23s - loss: 0.9566 - acc: 0.6776 - val_loss: 1.0593 - val_acc: 0.6494\n",
            "Epoch 5/20\n",
            " - 23s - loss: 0.9159 - acc: 0.6970 - val_loss: 0.9529 - val_acc: 0.6851\n",
            "Epoch 6/20\n",
            " - 23s - loss: 0.9112 - acc: 0.7039 - val_loss: 0.9401 - val_acc: 0.6896\n",
            "Epoch 7/20\n",
            " - 23s - loss: 0.9109 - acc: 0.7072 - val_loss: 0.8655 - val_acc: 0.7260\n",
            "Epoch 8/20\n",
            " - 23s - loss: 0.9147 - acc: 0.7105 - val_loss: 1.0572 - val_acc: 0.6397\n",
            "Epoch 9/20\n",
            " - 23s - loss: 0.9025 - acc: 0.7160 - val_loss: 1.1887 - val_acc: 0.6373\n",
            "Epoch 10/20\n",
            " - 23s - loss: 0.9063 - acc: 0.7194 - val_loss: 0.9254 - val_acc: 0.7091\n",
            "Epoch 11/20\n",
            " - 23s - loss: 0.9135 - acc: 0.7181 - val_loss: 0.9058 - val_acc: 0.7175\n",
            "Epoch 12/20\n",
            " - 23s - loss: 0.9168 - acc: 0.7191 - val_loss: 1.2229 - val_acc: 0.6820\n",
            "Epoch 13/20\n",
            " - 23s - loss: 0.9238 - acc: 0.7151 - val_loss: 0.9181 - val_acc: 0.7001\n",
            "Epoch 14/20\n",
            " - 23s - loss: 0.9212 - acc: 0.7200 - val_loss: 1.0046 - val_acc: 0.6609\n",
            "Epoch 15/20\n",
            " - 23s - loss: 0.9244 - acc: 0.7219 - val_loss: 0.9694 - val_acc: 0.6987\n",
            "Epoch 16/20\n",
            " - 23s - loss: 0.9135 - acc: 0.7223 - val_loss: 0.9805 - val_acc: 0.7047\n",
            "Epoch 17/20\n",
            " - 23s - loss: 0.9184 - acc: 0.7235 - val_loss: 1.0133 - val_acc: 0.6908\n",
            "Epoch 18/20\n",
            " - 23s - loss: 0.9303 - acc: 0.7258 - val_loss: 0.9677 - val_acc: 0.7010\n",
            "Epoch 19/20\n",
            " - 23s - loss: 0.9270 - acc: 0.7225 - val_loss: 0.9102 - val_acc: 0.7102\n",
            "Epoch 20/20\n",
            " - 23s - loss: 0.9485 - acc: 0.7287 - val_loss: 0.9817 - val_acc: 0.7237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f753a18b6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "YgJbTCmLoQZM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Network with augmented images, Architecture 4"
      ]
    },
    {
      "metadata": {
        "id": "t4jDPrqNIyqO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "aug_train = train_images[0:40000]\n",
        "aug_validate = train_images[40000:50000]\n",
        "\n",
        "#datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.15, zoom_range=0.1, channel_shift_range=10., horizontal_flip=True)\n",
        "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1, channel_shift_range=0.1, horizontal_flip=True)\n",
        "\n",
        "datagen.fit(aug_train)\n",
        "#test = [0, 1, 2, 3]\n",
        "#print(test[0:2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8hNpc4QnJnkG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_augmented = Sequential()\n",
        "\n",
        "CNN_augmented.add(layers.Conv2D(filters=32, kernel_size=(5, 5), activation='relu', input_shape=(32, 32, 3)))\n",
        "\n",
        "CNN_augmented.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "#CNN_augmented.add(Dropout(1 - .9))\n",
        "\n",
        "CNN_augmented.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "CNN_augmented.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2) )\n",
        "#CNN_augmented.add(Dropout(1 - .9))\n",
        "\n",
        "CNN_augmented.add(layers.Flatten())\n",
        "CNN_augmented.add(layers.Dense(512, activation='relu'))\n",
        "#CNN_augmented.add(Dropout(1 - .9))\n",
        "\n",
        "CNN_augmented.add(layers.Dense(10, activation='softmax')) \n",
        "#CNN.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aFYuW6VMJn4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "c44a7387-0060-4af6-be2a-2abfe03d70eb"
      },
      "cell_type": "code",
      "source": [
        "rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)  # default values: RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
        "CNN_augmented.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#CNN_augmented.fit(x=train_images_bw, y=train_labels, batch_size=32, epochs=20, verbose=2, validation_split=0.2, shuffle=True)\n",
        "\n",
        "CNN_augmented.fit_generator(datagen.flow(train_images[0:40000], train_labels[0:40000], batch_size=32),\n",
        "                    steps_per_epoch=ceil(40000 / 32), epochs=20, verbose=1, validation_data=(train_images[40000:50000], train_labels[40000:50000]))#, validation_split=0.2, shuffle=True)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1250/1250 [==============================] - 31s 25ms/step - loss: 1.6156 - acc: 0.4234 - val_loss: 1.2398 - val_acc: 0.5628\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 1.2868 - acc: 0.5462 - val_loss: 1.2377 - val_acc: 0.5745\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.1690 - acc: 0.5934 - val_loss: 1.0451 - val_acc: 0.6382\n",
            "Epoch 4/20\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 1.1075 - acc: 0.6180 - val_loss: 0.9617 - val_acc: 0.6671\n",
            "Epoch 5/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.0752 - acc: 0.6318 - val_loss: 0.9626 - val_acc: 0.6763\n",
            "Epoch 6/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.0430 - acc: 0.6419 - val_loss: 0.9489 - val_acc: 0.6821\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.0300 - acc: 0.6489 - val_loss: 0.9968 - val_acc: 0.6738\n",
            "Epoch 8/20\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.0225 - acc: 0.6537 - val_loss: 1.2902 - val_acc: 0.6157\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.0123 - acc: 0.6580 - val_loss: 1.0015 - val_acc: 0.6686\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.0022 - acc: 0.6610 - val_loss: 0.9703 - val_acc: 0.6809\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9980 - acc: 0.6653 - val_loss: 0.8858 - val_acc: 0.7104\n",
            "Epoch 12/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9973 - acc: 0.6648 - val_loss: 0.8994 - val_acc: 0.6958\n",
            "Epoch 13/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9923 - acc: 0.6643 - val_loss: 0.9441 - val_acc: 0.6908\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9960 - acc: 0.6643 - val_loss: 0.9618 - val_acc: 0.6764\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9857 - acc: 0.6712 - val_loss: 1.0355 - val_acc: 0.6759\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9866 - acc: 0.6751 - val_loss: 0.9523 - val_acc: 0.7010\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9895 - acc: 0.6732 - val_loss: 0.9790 - val_acc: 0.6796\n",
            "Epoch 18/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 0.9928 - acc: 0.6696 - val_loss: 0.9215 - val_acc: 0.7030\n",
            "Epoch 19/20\n",
            "1250/1250 [==============================] - 29s 24ms/step - loss: 0.9873 - acc: 0.6747 - val_loss: 1.0055 - val_acc: 0.6743\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9917 - acc: 0.6700 - val_loss: 0.9009 - val_acc: 0.7118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f753ac675f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "KVtwCiz4X_QE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### \"Train this final architecture on the data from the training set and validation set and evaluate its performance on the test set.\""
      ]
    },
    {
      "metadata": {
        "id": "Xe8mn1CiX-b1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "outputId": "d181bbb3-43c8-4b44-de82-5eb457861b61"
      },
      "cell_type": "code",
      "source": [
        "CNN_expanded = Sequential()\n",
        "\n",
        "CNN_expanded.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "CNN_expanded.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "CNN_expanded.add(Dropout(1 - 0.95))\n",
        "\n",
        "CNN_expanded.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "CNN_expanded.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2) )\n",
        "CNN_expanded.add(Dropout(1 - 0.95))\n",
        "\n",
        "CNN_expanded.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "CNN_expanded.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2) )\n",
        "CNN_expanded.add(Dropout(1 - 0.95))\n",
        "\n",
        "CNN_expanded.add(layers.Flatten())\n",
        "CNN_expanded.add(layers.Dense(512, activation='relu'))\n",
        "CNN_expanded.add(Dropout(1 - 0.95))\n",
        "\n",
        "CNN_expanded.add(layers.Dense(256, activation='relu'))\n",
        "CNN_expanded.add(Dropout(1 - 0.95))\n",
        "\n",
        "CNN_expanded.add(layers.Dense(128, activation='relu'))\n",
        "\n",
        "CNN_expanded.add(layers.Dense(10, activation='softmax')) \n",
        "\n",
        "\n",
        "rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)  # default values: RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
        "CNN_expanded.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "CNN_expanded.fit(x=train_images, y=train_labels, batch_size=32, epochs=20, verbose=1, shuffle=True)\n",
        "score = CNN_expanded.evaluate(test_images, test_labels, batch_size=32)\n",
        "print()\n",
        "print(str(score[1] * 100) + \"% accuracy\")"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 32s 640us/step - loss: 1.5697 - acc: 0.4304\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 30s 608us/step - loss: 1.1322 - acc: 0.6077\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 30s 607us/step - loss: 0.9944 - acc: 0.6649\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 30s 609us/step - loss: 0.9511 - acc: 0.6829\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 30s 609us/step - loss: 0.9469 - acc: 0.6901\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 30s 608us/step - loss: 0.9451 - acc: 0.6966\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 30s 609us/step - loss: 0.9486 - acc: 0.7002\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 30s 608us/step - loss: 0.9640 - acc: 0.6979\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 30s 608us/step - loss: 0.9618 - acc: 0.7012\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 30s 608us/step - loss: 0.9605 - acc: 0.7045\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 30s 609us/step - loss: 0.9726 - acc: 0.7023\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 30s 610us/step - loss: 0.9825 - acc: 0.6995\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 30s 609us/step - loss: 0.9808 - acc: 0.7026\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 30s 609us/step - loss: 0.9825 - acc: 0.7037\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 30s 610us/step - loss: 1.0134 - acc: 0.7037\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 30s 608us/step - loss: 1.0033 - acc: 0.6986\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 30s 609us/step - loss: 0.9981 - acc: 0.7028\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 30s 607us/step - loss: 1.0235 - acc: 0.6990\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 30s 609us/step - loss: 1.1778 - acc: 0.6944\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 30s 610us/step - loss: 1.0082 - acc: 0.6951\n",
            "10000/10000 [==============================] - 3s 259us/step\n",
            "\n",
            "67.85% accuracy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iAfq3uvhYyC0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reevaluate your best architecture using k-fold validation with k=5, that is, the size of the validation fold is 20%. Does the accuracy/loss obtain by k-fold validation differ from the accuracy/loss obtain by simple hold-out validation."
      ]
    },
    {
      "metadata": {
        "id": "JUCPDPOIGsZw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3461
        },
        "outputId": "905db927-49c6-4985-c0ad-f8be05b76047"
      },
      "cell_type": "code",
      "source": [
        "# Folds (validation sets):\n",
        "fold1 = train_images[0:10000]\n",
        "fold2 = train_images[10000:20000]\n",
        "fold3 = train_images[20000:30000]\n",
        "fold4 = train_images[30000:40000]\n",
        "fold5 = train_images[40000:50000]\n",
        "folds = [fold1,fold2,fold3,fold4,fold5] \n",
        "\n",
        "fold_label_set1 = train_labels[0:10000]\n",
        "fold_label_set2 = train_labels[10000:20000]\n",
        "fold_label_set3 = train_labels[20000:30000]\n",
        "fold_label_set4 = train_labels[30000:40000]\n",
        "fold_label_set5 = train_labels[40000:50000]\n",
        "fold_labels = [fold_label_set1,fold_label_set2,fold_label_set3,fold_label_set4,fold_label_set5] \n",
        "\n",
        "# Train sets\n",
        "train1 = train_images[10000:50000]\n",
        "train2 = np.concatenate((train_images[0:10000], train_images[20000:50000]))\n",
        "train3 = np.concatenate((train_images[0:20000], train_images[30000:50000]))\n",
        "train4 = np.concatenate((train_images[0:30000], train_images[40000:50000]))\n",
        "train5 = train_images[0:40000]\n",
        "train_sets = [train1,train2,train3,train4,train5]\n",
        "\n",
        "trainlabel1 = train_labels[10000:50000]\n",
        "trainlabel2 = np.concatenate((train_labels[0:10000], train_labels[20000:50000]))\n",
        "trainlabel3 = np.concatenate((train_labels[0:20000], train_labels[30000:50000]))\n",
        "trainlabel4 = np.concatenate((train_labels[0:30000], train_labels[40000:50000]))\n",
        "trainlabel5 = train_labels[0:40000]\n",
        "train_label_sets = [trainlabel1,trainlabel2,trainlabel3,trainlabel4,trainlabel5]\n",
        "\n",
        "\n",
        "for fold,fold_label_set,train_set,train_label_set in zip(folds,fold_labels,train_sets,train_label_sets):\n",
        "    \n",
        "    datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1, channel_shift_range=0.1, horizontal_flip=True)\n",
        "    datagen.fit(train_set)\n",
        "\n",
        "    CNN_final = Sequential()\n",
        "    CNN_final.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    CNN_final.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "    CNN_final.add(Dropout(1 - 0.95))\n",
        "    CNN_final.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    CNN_final.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2) )\n",
        "    CNN_final.add(Dropout(1 - 0.95))\n",
        "    CNN_final.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "    CNN_final.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2) )\n",
        "    CNN_final.add(Dropout(1 - 0.95))\n",
        "    CNN_final.add(layers.Flatten())\n",
        "    CNN_final.add(layers.Dense(512, activation='relu'))\n",
        "    CNN_final.add(Dropout(1 - 0.95))\n",
        "    CNN_final.add(layers.Dense(256, activation='relu'))\n",
        "    CNN_final.add(Dropout(1 - 0.95))\n",
        "    CNN_final.add(layers.Dense(128, activation='relu'))\n",
        "    CNN_final.add(layers.Dense(10, activation='softmax')) \n",
        "\n",
        "    rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
        "    CNN_final.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    CNN_final.fit_generator(datagen.flow(train_set, train_label_set, batch_size=32), steps_per_epoch=ceil(40000 / 32), epochs=20, verbose=1, validation_data=(fold, fold_label_set))\n",
        "    print()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1250/1250 [==============================] - 37s 29ms/step - loss: 1.7661 - acc: 0.3528 - val_loss: 1.3956 - val_acc: 0.4949\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - 35s 28ms/step - loss: 1.3799 - acc: 0.5119 - val_loss: 1.1630 - val_acc: 0.5946\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - 35s 28ms/step - loss: 1.2383 - acc: 0.5684 - val_loss: 1.0102 - val_acc: 0.6487\n",
            "Epoch 4/20\n",
            "1250/1250 [==============================] - 35s 28ms/step - loss: 1.1858 - acc: 0.5926 - val_loss: 1.2282 - val_acc: 0.5738\n",
            "Epoch 5/20\n",
            "1250/1250 [==============================] - 35s 28ms/step - loss: 1.1801 - acc: 0.5991 - val_loss: 1.0767 - val_acc: 0.6389\n",
            "Epoch 6/20\n",
            "1250/1250 [==============================] - 36s 28ms/step - loss: 1.1842 - acc: 0.6073 - val_loss: 1.0566 - val_acc: 0.6682\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.1873 - acc: 0.6044 - val_loss: 0.9961 - val_acc: 0.6619\n",
            "Epoch 8/20\n",
            "1250/1250 [==============================] - 35s 28ms/step - loss: 1.1951 - acc: 0.6064 - val_loss: 1.1030 - val_acc: 0.6243\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - 35s 28ms/step - loss: 1.1803 - acc: 0.6130 - val_loss: 0.9873 - val_acc: 0.6604\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - 36s 28ms/step - loss: 1.2030 - acc: 0.6117 - val_loss: 1.0683 - val_acc: 0.6558\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2119 - acc: 0.6055 - val_loss: 1.2669 - val_acc: 0.5729\n",
            "Epoch 12/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2099 - acc: 0.6105 - val_loss: 1.2780 - val_acc: 0.5969\n",
            "Epoch 13/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2113 - acc: 0.6114 - val_loss: 1.2598 - val_acc: 0.6206\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - 35s 28ms/step - loss: 1.2265 - acc: 0.6065 - val_loss: 1.2367 - val_acc: 0.6414\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - 37s 30ms/step - loss: 1.2187 - acc: 0.6110 - val_loss: 1.1794 - val_acc: 0.6194\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - 37s 29ms/step - loss: 1.2192 - acc: 0.6090 - val_loss: 1.0183 - val_acc: 0.6581\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2143 - acc: 0.6099 - val_loss: 1.0542 - val_acc: 0.6514\n",
            "Epoch 18/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.2329 - acc: 0.6098 - val_loss: 0.9346 - val_acc: 0.6976\n",
            "Epoch 19/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.2338 - acc: 0.6088 - val_loss: 1.0173 - val_acc: 0.6796\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - 39s 31ms/step - loss: 1.2506 - acc: 0.6069 - val_loss: 0.9965 - val_acc: 0.6666\n",
            "\n",
            "Epoch 1/20\n",
            "1250/1250 [==============================] - 40s 32ms/step - loss: 1.7394 - acc: 0.3630 - val_loss: 1.6364 - val_acc: 0.4690\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.3697 - acc: 0.5124 - val_loss: 1.2240 - val_acc: 0.5781\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - 37s 30ms/step - loss: 1.2385 - acc: 0.5699 - val_loss: 1.0267 - val_acc: 0.6422\n",
            "Epoch 4/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.1880 - acc: 0.5962 - val_loss: 0.9930 - val_acc: 0.6622\n",
            "Epoch 5/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.1662 - acc: 0.6059 - val_loss: 1.0402 - val_acc: 0.6430\n",
            "Epoch 6/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.1690 - acc: 0.6098 - val_loss: 1.0146 - val_acc: 0.6558\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - 38s 31ms/step - loss: 1.1851 - acc: 0.6068 - val_loss: 0.9848 - val_acc: 0.6635\n",
            "Epoch 8/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.1788 - acc: 0.6152 - val_loss: 1.0548 - val_acc: 0.6354\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - 38s 31ms/step - loss: 1.1760 - acc: 0.6138 - val_loss: 1.0036 - val_acc: 0.6579\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - 38s 31ms/step - loss: 1.1935 - acc: 0.6141 - val_loss: 1.1314 - val_acc: 0.6585\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.2063 - acc: 0.6109 - val_loss: 0.9848 - val_acc: 0.6721\n",
            "Epoch 12/20\n",
            "1250/1250 [==============================] - 38s 31ms/step - loss: 1.2337 - acc: 0.6050 - val_loss: 1.0452 - val_acc: 0.6586\n",
            "Epoch 13/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.2202 - acc: 0.6101 - val_loss: 0.9769 - val_acc: 0.6840\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.1922 - acc: 0.6195 - val_loss: 1.0599 - val_acc: 0.6479\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - 38s 31ms/step - loss: 1.2174 - acc: 0.6166 - val_loss: 0.8505 - val_acc: 0.7237\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - 37s 30ms/step - loss: 1.2029 - acc: 0.6137 - val_loss: 1.0139 - val_acc: 0.6657\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - 37s 30ms/step - loss: 1.2037 - acc: 0.6164 - val_loss: 0.9662 - val_acc: 0.6796\n",
            "Epoch 18/20\n",
            "1250/1250 [==============================] - 37s 30ms/step - loss: 1.2227 - acc: 0.6109 - val_loss: 0.9596 - val_acc: 0.6908\n",
            "Epoch 19/20\n",
            "1250/1250 [==============================] - 37s 30ms/step - loss: 1.2284 - acc: 0.6156 - val_loss: 1.0066 - val_acc: 0.6714\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - 38s 31ms/step - loss: 1.2250 - acc: 0.6171 - val_loss: 1.0258 - val_acc: 0.6901\n",
            "\n",
            "Epoch 1/20\n",
            "1250/1250 [==============================] - 39s 31ms/step - loss: 1.7448 - acc: 0.3583 - val_loss: 1.3345 - val_acc: 0.5178\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.3656 - acc: 0.5160 - val_loss: 1.1760 - val_acc: 0.5925\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - 37s 30ms/step - loss: 1.2316 - acc: 0.5758 - val_loss: 0.9818 - val_acc: 0.6643\n",
            "Epoch 4/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.1761 - acc: 0.6020 - val_loss: 0.9457 - val_acc: 0.6765\n",
            "Epoch 5/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.1590 - acc: 0.6102 - val_loss: 1.0939 - val_acc: 0.6259\n",
            "Epoch 6/20\n",
            "1250/1250 [==============================] - 37s 30ms/step - loss: 1.1574 - acc: 0.6134 - val_loss: 0.9108 - val_acc: 0.6908\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.1608 - acc: 0.6155 - val_loss: 0.9686 - val_acc: 0.6735\n",
            "Epoch 8/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.1739 - acc: 0.6138 - val_loss: 1.1035 - val_acc: 0.6302\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.1714 - acc: 0.6143 - val_loss: 1.1801 - val_acc: 0.5998\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.1542 - acc: 0.6221 - val_loss: 1.0671 - val_acc: 0.6494\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - 37s 30ms/step - loss: 1.1721 - acc: 0.6183 - val_loss: 0.9038 - val_acc: 0.7109\n",
            "Epoch 12/20\n",
            "1250/1250 [==============================] - 38s 31ms/step - loss: 1.1771 - acc: 0.6205 - val_loss: 0.9818 - val_acc: 0.6765\n",
            "Epoch 13/20\n",
            "1250/1250 [==============================] - 37s 30ms/step - loss: 1.1796 - acc: 0.6200 - val_loss: 1.1030 - val_acc: 0.6535\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - 38s 31ms/step - loss: 1.1749 - acc: 0.6232 - val_loss: 1.0595 - val_acc: 0.6321\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - 37s 30ms/step - loss: 1.1879 - acc: 0.6218 - val_loss: 0.9547 - val_acc: 0.6666\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.2137 - acc: 0.6160 - val_loss: 1.0536 - val_acc: 0.6534\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.2283 - acc: 0.6152 - val_loss: 1.0161 - val_acc: 0.6712\n",
            "Epoch 18/20\n",
            "1250/1250 [==============================] - 37s 30ms/step - loss: 1.2296 - acc: 0.6109 - val_loss: 1.3160 - val_acc: 0.5625\n",
            "Epoch 19/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.2320 - acc: 0.6150 - val_loss: 1.0926 - val_acc: 0.6338\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - 37s 29ms/step - loss: 1.2316 - acc: 0.6180 - val_loss: 1.0660 - val_acc: 0.6904\n",
            "\n",
            "Epoch 1/20\n",
            "1250/1250 [==============================] - 41s 33ms/step - loss: 1.7461 - acc: 0.3568 - val_loss: 1.4349 - val_acc: 0.4754\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - 37s 30ms/step - loss: 1.3658 - acc: 0.5161 - val_loss: 1.2852 - val_acc: 0.5449\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - 38s 31ms/step - loss: 1.2285 - acc: 0.5734 - val_loss: 1.0909 - val_acc: 0.6259\n",
            "Epoch 4/20\n",
            "1250/1250 [==============================] - 39s 31ms/step - loss: 1.1729 - acc: 0.5968 - val_loss: 1.0390 - val_acc: 0.6394\n",
            "Epoch 5/20\n",
            "1250/1250 [==============================] - 38s 31ms/step - loss: 1.1776 - acc: 0.6052 - val_loss: 1.0434 - val_acc: 0.6459\n",
            "Epoch 6/20\n",
            "1250/1250 [==============================] - 38s 31ms/step - loss: 1.1776 - acc: 0.6053 - val_loss: 1.0665 - val_acc: 0.6554\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - 37s 30ms/step - loss: 1.1795 - acc: 0.6122 - val_loss: 1.0180 - val_acc: 0.6440\n",
            "Epoch 8/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.1764 - acc: 0.6117 - val_loss: 0.9649 - val_acc: 0.6699\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.1876 - acc: 0.6120 - val_loss: 0.9809 - val_acc: 0.6760\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.1972 - acc: 0.6064 - val_loss: 1.0139 - val_acc: 0.6698\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2172 - acc: 0.6061 - val_loss: 1.1123 - val_acc: 0.6625\n",
            "Epoch 12/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2319 - acc: 0.6049 - val_loss: 1.1379 - val_acc: 0.6354\n",
            "Epoch 13/20\n",
            "1250/1250 [==============================] - 37s 29ms/step - loss: 1.2333 - acc: 0.6061 - val_loss: 1.0668 - val_acc: 0.6341\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2423 - acc: 0.6008 - val_loss: 1.2792 - val_acc: 0.5455\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2174 - acc: 0.6113 - val_loss: 1.2737 - val_acc: 0.5762\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2127 - acc: 0.6095 - val_loss: 0.9826 - val_acc: 0.6716\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2203 - acc: 0.6079 - val_loss: 1.0991 - val_acc: 0.6217\n",
            "Epoch 18/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2438 - acc: 0.6050 - val_loss: 1.0109 - val_acc: 0.6592\n",
            "Epoch 19/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2370 - acc: 0.6076 - val_loss: 0.9498 - val_acc: 0.6911\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2801 - acc: 0.6037 - val_loss: 1.1167 - val_acc: 0.6464\n",
            "\n",
            "Epoch 1/20\n",
            "1250/1250 [==============================] - 39s 31ms/step - loss: 1.7364 - acc: 0.3665 - val_loss: 1.3409 - val_acc: 0.5292\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - 37s 30ms/step - loss: 1.3841 - acc: 0.5088 - val_loss: 1.2922 - val_acc: 0.5531\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2435 - acc: 0.5672 - val_loss: 1.1331 - val_acc: 0.6113\n",
            "Epoch 4/20\n",
            "1250/1250 [==============================] - 37s 29ms/step - loss: 1.1875 - acc: 0.5935 - val_loss: 1.1664 - val_acc: 0.6082\n",
            "Epoch 5/20\n",
            "1250/1250 [==============================] - 36s 28ms/step - loss: 1.1616 - acc: 0.6049 - val_loss: 1.0164 - val_acc: 0.6571\n",
            "Epoch 6/20\n",
            "1250/1250 [==============================] - 36s 28ms/step - loss: 1.1604 - acc: 0.6091 - val_loss: 1.0185 - val_acc: 0.6559\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.1849 - acc: 0.6061 - val_loss: 1.4446 - val_acc: 0.5248\n",
            "Epoch 8/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2052 - acc: 0.6089 - val_loss: 1.1231 - val_acc: 0.6374\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.1881 - acc: 0.6085 - val_loss: 1.2658 - val_acc: 0.6254\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 1.1980 - acc: 0.6098 - val_loss: 1.0158 - val_acc: 0.6429\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2049 - acc: 0.6119 - val_loss: 0.8689 - val_acc: 0.7188\n",
            "Epoch 12/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.1913 - acc: 0.6143 - val_loss: 1.3527 - val_acc: 0.6403\n",
            "Epoch 13/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2050 - acc: 0.6145 - val_loss: 1.0100 - val_acc: 0.6707\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.1920 - acc: 0.6182 - val_loss: 1.2961 - val_acc: 0.5768\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.1952 - acc: 0.6182 - val_loss: 1.1229 - val_acc: 0.6265\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2111 - acc: 0.6122 - val_loss: 0.9203 - val_acc: 0.6931\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2338 - acc: 0.6092 - val_loss: 0.9890 - val_acc: 0.6762\n",
            "Epoch 18/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2355 - acc: 0.6107 - val_loss: 1.0955 - val_acc: 0.6362\n",
            "Epoch 19/20\n",
            "1250/1250 [==============================] - 37s 29ms/step - loss: 1.2599 - acc: 0.6023 - val_loss: 1.0158 - val_acc: 0.6757\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 1.2534 - acc: 0.6037 - val_loss: 1.0386 - val_acc: 0.6882\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}