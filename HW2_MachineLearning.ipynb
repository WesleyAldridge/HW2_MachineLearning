{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2_MachineLearning",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WesleyAldridge/HW2_MachineLearning/blob/master/HW2_MachineLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rt44vyY1xW9b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## HW2 - Convolutional Neural Network For CIFAR10 Data Set"
      ]
    },
    {
      "metadata": {
        "id": "Pfuun9431eEs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Instructions from professor:\n",
        "\n",
        "\"The goal of this homework is to create a convolutional neural network for the CIFAR10 data set.\n",
        "\n",
        "You should not use any pretrained convnets that come with Keras. You have to create and train your own convnets with Keras from scratch.\n",
        "\n",
        "Make sure that the data is divided into:\n",
        "\n",
        "- training set (80%)\n",
        "- validation set (20%)\n",
        "- test set.\n",
        "\n",
        "Use the training set to train your neural networks. Evaluate their performance on the validation data set.\n",
        "\n",
        "After trying several different architectures, choose the one that performs best on the validation set. Try at least four different architectures by using data augmentation, using dropout, varying the number of layers, the number of filters, etc.\n",
        "\n",
        "Train this final architecture on the data from the training set and validation set and evaluate its performance on the test set.\n",
        "\n",
        "Reevaluate your best architecture using k-fold validation with k=5, that is, the size of the validation fold is 20%. Does the accuracy/loss obtain by k-fold validation differ from the accuracy/loss obtain by simple hold-out validation."
      ]
    },
    {
      "metadata": {
        "id": "l34GNy7tyNks",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loading the CIFAR10 data set"
      ]
    },
    {
      "metadata": {
        "id": "qICX25UpB4W0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**train_images.shape = (50000, 32, 32, 3)**\n",
        "\n",
        "**test_images.shape  = (10000, 32, 32, 3) **\n",
        "\n",
        "50,000 train_images of shape 32x32 pixels, made up of 3 channels (R,G,B)\n",
        "\n",
        "10,000 test_images of shape 32x32 pixels, made up of 3 channels (R,G,B)"
      ]
    },
    {
      "metadata": {
        "id": "FSJyddqGexl5",
        "colab_type": "code",
        "outputId": "f3ab64d2-c9bc-43f2-dea6-b6f196d5db29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as mpl\n",
        "from math import ceil\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels, 10)\n",
        "test_labels = to_categorical(test_labels, 10)\n",
        "\n",
        "train_images.shape, test_images[0][0][0]#.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3),\n",
              " array([0.61960787, 0.4392157 , 0.19215687], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "NqoZq8yYBBvp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Making Basic CNN, Architecture 1"
      ]
    },
    {
      "metadata": {
        "id": "wLs7MsrVKae1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Example CNN from class notes:\n",
        "\n",
        "Input Images > Conv2d (ReLU) > MaxPool > Conv2d (ReLU) > MaxPool > Fully Connected > Fully Connected (output) \n",
        "\n",
        "This is two convolution modules (convolution(ReLU) + pooling) for feature extraction, and two fully connected layers for classification."
      ]
    },
    {
      "metadata": {
        "id": "8ES8_yvjAVfP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_basic = Sequential()\n",
        "\n",
        "# \"To start, the CNN receives an input feature map: a 3-dimensional matrix, where\n",
        "# the size of the first two dimensions corresponds to the length and width of the\n",
        "# images in pixels, and the size of the third dimension is 3 (corresponding to the\n",
        "# 3 channels of a color image: red, green, and blue).\" - class notes\n",
        "\n",
        "# \"A convolution extracts tiles of the input feature map, and applies filters to them\n",
        "# to compute new features, producing an output feature map, or convolved feature\n",
        "# (which may have a different size and depth than the input feature map)\n",
        "# Convolutions are defined by two parameters:\n",
        "# Size of the tiles that are extracted (typically 3x3 or 5x5 pixels).\n",
        "# The depth of the output feature map, which corresponds to the number of filters\n",
        "# that are applied.\" - class notes\n",
        "\n",
        "# \"After each convolution operation, the CNN applies a Rectified Linear Unit (ReLU)\n",
        "# transformation to the convolved feature, in order to introduce nonlinearity into\n",
        "# the model\" - class notes\n",
        "CNN_basic.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "\n",
        "# \"After ReLU comes a pooling step, in which the CNN downsamples the convolved feature\n",
        "# (to save on processing time), reducing the number of dimensions of the feature map,\n",
        "# while still preserving the most critical feature information.\" - class notes\n",
        "\n",
        "# \"size of the max-pooling filter is typically 2x2 pixels\" - from class notes\n",
        "# the class notes talk about using a stride of 2, so I will use that here as well:\n",
        "CNN_basic.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "CNN_basic.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "CNN_basic.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2) )\n",
        "\n",
        "CNN_basic.add(layers.Flatten())\n",
        "CNN_basic.add(layers.Dense(512, activation='relu'))\n",
        "# \"Typically, the final fully-connected layer contains a softmax activation function,\n",
        "# which outputs a probability value from 0 to 1 for each of the classification labels\n",
        "# the model is trying to predict\" - class notes\n",
        "CNN_basic.add(layers.Dense(10, activation='softmax')) \n",
        "#CNN.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2MGYWy7wXZZi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluating on validation set:"
      ]
    },
    {
      "metadata": {
        "id": "U3wmUq8ESbjn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1730
        },
        "outputId": "73a97487-aab4-4e5f-8c1f-09cc1f83927b"
      },
      "cell_type": "code",
      "source": [
        "rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)  # default values: RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
        "CNN_basic.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "CNN_basic.fit(x=train_images, y=train_labels, batch_size=32, epochs=20, verbose=1, validation_split=0.2, shuffle=True)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "40000/40000 [==============================] - 13s 332us/step - loss: 1.4596 - acc: 0.4780 - val_loss: 1.1781 - val_acc: 0.5881\n",
            "Epoch 2/50\n",
            "40000/40000 [==============================] - 12s 304us/step - loss: 1.0576 - acc: 0.6318 - val_loss: 1.1722 - val_acc: 0.5885\n",
            "Epoch 3/50\n",
            "40000/40000 [==============================] - 12s 303us/step - loss: 0.8764 - acc: 0.6974 - val_loss: 0.9738 - val_acc: 0.6701\n",
            "Epoch 4/50\n",
            "40000/40000 [==============================] - 12s 303us/step - loss: 0.7327 - acc: 0.7479 - val_loss: 0.9638 - val_acc: 0.6833\n",
            "Epoch 5/50\n",
            "40000/40000 [==============================] - 12s 303us/step - loss: 0.6029 - acc: 0.7935 - val_loss: 0.9288 - val_acc: 0.7055\n",
            "Epoch 6/50\n",
            "40000/40000 [==============================] - 12s 299us/step - loss: 0.4953 - acc: 0.8307 - val_loss: 1.0302 - val_acc: 0.7002\n",
            "Epoch 7/50\n",
            "40000/40000 [==============================] - 12s 298us/step - loss: 0.4097 - acc: 0.8619 - val_loss: 1.1078 - val_acc: 0.6832\n",
            "Epoch 8/50\n",
            "40000/40000 [==============================] - 12s 299us/step - loss: 0.3408 - acc: 0.8883 - val_loss: 1.1880 - val_acc: 0.7088\n",
            "Epoch 9/50\n",
            "40000/40000 [==============================] - 12s 303us/step - loss: 0.2849 - acc: 0.9061 - val_loss: 1.3052 - val_acc: 0.7041\n",
            "Epoch 10/50\n",
            "40000/40000 [==============================] - 12s 299us/step - loss: 0.2486 - acc: 0.9186 - val_loss: 1.3576 - val_acc: 0.7013\n",
            "Epoch 11/50\n",
            "40000/40000 [==============================] - 12s 297us/step - loss: 0.2306 - acc: 0.9257 - val_loss: 1.6424 - val_acc: 0.7026\n",
            "Epoch 12/50\n",
            "40000/40000 [==============================] - 12s 296us/step - loss: 0.2128 - acc: 0.9329 - val_loss: 1.6275 - val_acc: 0.6975\n",
            "Epoch 13/50\n",
            "40000/40000 [==============================] - 12s 297us/step - loss: 0.2036 - acc: 0.9359 - val_loss: 2.0961 - val_acc: 0.6798\n",
            "Epoch 14/50\n",
            "40000/40000 [==============================] - 12s 297us/step - loss: 0.1903 - acc: 0.9415 - val_loss: 2.0611 - val_acc: 0.7022\n",
            "Epoch 15/50\n",
            "40000/40000 [==============================] - 12s 298us/step - loss: 0.1763 - acc: 0.9455 - val_loss: 1.7745 - val_acc: 0.6779\n",
            "Epoch 16/50\n",
            "40000/40000 [==============================] - 12s 301us/step - loss: 0.1732 - acc: 0.9478 - val_loss: 2.1944 - val_acc: 0.6752\n",
            "Epoch 17/50\n",
            "40000/40000 [==============================] - 12s 294us/step - loss: 0.1775 - acc: 0.9474 - val_loss: 2.0223 - val_acc: 0.6958\n",
            "Epoch 18/50\n",
            "40000/40000 [==============================] - 12s 292us/step - loss: 0.1756 - acc: 0.9489 - val_loss: 2.1969 - val_acc: 0.7032\n",
            "Epoch 19/50\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 0.1721 - acc: 0.9496 - val_loss: 2.5664 - val_acc: 0.6709\n",
            "Epoch 20/50\n",
            "40000/40000 [==============================] - 12s 294us/step - loss: 0.1722 - acc: 0.9516 - val_loss: 2.3857 - val_acc: 0.6915\n",
            "Epoch 21/50\n",
            "40000/40000 [==============================] - 12s 294us/step - loss: 0.1695 - acc: 0.9523 - val_loss: 2.2081 - val_acc: 0.6844\n",
            "Epoch 22/50\n",
            "40000/40000 [==============================] - 12s 292us/step - loss: 0.1622 - acc: 0.9541 - val_loss: 2.2680 - val_acc: 0.6878\n",
            "Epoch 23/50\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 0.1523 - acc: 0.9564 - val_loss: 2.4055 - val_acc: 0.7022\n",
            "Epoch 24/50\n",
            "40000/40000 [==============================] - 12s 294us/step - loss: 0.1565 - acc: 0.9587 - val_loss: 2.6232 - val_acc: 0.7011\n",
            "Epoch 25/50\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 0.1636 - acc: 0.9576 - val_loss: 2.6966 - val_acc: 0.6976\n",
            "Epoch 26/50\n",
            "40000/40000 [==============================] - 12s 294us/step - loss: 0.1590 - acc: 0.9595 - val_loss: 2.5702 - val_acc: 0.7040\n",
            "Epoch 27/50\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.1533 - acc: 0.9601 - val_loss: 2.3557 - val_acc: 0.6822\n",
            "Epoch 28/50\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 0.1509 - acc: 0.9619 - val_loss: 2.7608 - val_acc: 0.6820\n",
            "Epoch 29/50\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.1648 - acc: 0.9602 - val_loss: 2.7709 - val_acc: 0.6747\n",
            "Epoch 30/50\n",
            "40000/40000 [==============================] - 12s 292us/step - loss: 0.1469 - acc: 0.9631 - val_loss: 2.7224 - val_acc: 0.6943\n",
            "Epoch 31/50\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 0.1568 - acc: 0.9632 - val_loss: 3.0544 - val_acc: 0.6835\n",
            "Epoch 32/50\n",
            "40000/40000 [==============================] - 12s 294us/step - loss: 0.1567 - acc: 0.9632 - val_loss: 3.2671 - val_acc: 0.6761\n",
            "Epoch 33/50\n",
            "40000/40000 [==============================] - 12s 293us/step - loss: 0.1563 - acc: 0.9627 - val_loss: 2.7960 - val_acc: 0.6769\n",
            "Epoch 34/50\n",
            "40000/40000 [==============================] - 12s 294us/step - loss: 0.1454 - acc: 0.9660 - val_loss: 3.1521 - val_acc: 0.6604\n",
            "Epoch 35/50\n",
            "40000/40000 [==============================] - 12s 298us/step - loss: 0.1476 - acc: 0.9663 - val_loss: 2.8692 - val_acc: 0.6962\n",
            "Epoch 36/50\n",
            "40000/40000 [==============================] - 12s 298us/step - loss: 0.1591 - acc: 0.9649 - val_loss: 2.8632 - val_acc: 0.6806\n",
            "Epoch 37/50\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.1427 - acc: 0.9677 - val_loss: 3.4456 - val_acc: 0.6894\n",
            "Epoch 38/50\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.1483 - acc: 0.9659 - val_loss: 3.1225 - val_acc: 0.6864\n",
            "Epoch 39/50\n",
            "40000/40000 [==============================] - 11s 286us/step - loss: 0.1521 - acc: 0.9679 - val_loss: 3.4851 - val_acc: 0.6644\n",
            "Epoch 40/50\n",
            "40000/40000 [==============================] - 11s 287us/step - loss: 0.1453 - acc: 0.9692 - val_loss: 3.0099 - val_acc: 0.6742\n",
            "Epoch 41/50\n",
            "40000/40000 [==============================] - 11s 285us/step - loss: 0.1418 - acc: 0.9699 - val_loss: 3.0019 - val_acc: 0.6855\n",
            "Epoch 42/50\n",
            "40000/40000 [==============================] - 12s 290us/step - loss: 0.1535 - acc: 0.9684 - val_loss: 3.2797 - val_acc: 0.6877\n",
            "Epoch 43/50\n",
            "40000/40000 [==============================] - 11s 285us/step - loss: 0.1440 - acc: 0.9701 - val_loss: 3.2443 - val_acc: 0.6896\n",
            "Epoch 44/50\n",
            "40000/40000 [==============================] - 11s 283us/step - loss: 0.1529 - acc: 0.9696 - val_loss: 3.1894 - val_acc: 0.6798\n",
            "Epoch 45/50\n",
            "40000/40000 [==============================] - 11s 283us/step - loss: 0.1519 - acc: 0.9700 - val_loss: 3.0973 - val_acc: 0.6912\n",
            "Epoch 46/50\n",
            "40000/40000 [==============================] - 11s 283us/step - loss: 0.1545 - acc: 0.9705 - val_loss: 3.3632 - val_acc: 0.7028\n",
            "Epoch 47/50\n",
            "40000/40000 [==============================] - 11s 286us/step - loss: 0.1456 - acc: 0.9708 - val_loss: 3.2992 - val_acc: 0.6893\n",
            "Epoch 48/50\n",
            "40000/40000 [==============================] - 11s 285us/step - loss: 0.1476 - acc: 0.9709 - val_loss: 3.1075 - val_acc: 0.6654\n",
            "Epoch 49/50\n",
            "40000/40000 [==============================] - 11s 285us/step - loss: 0.1495 - acc: 0.9717 - val_loss: 3.5682 - val_acc: 0.6971\n",
            "Epoch 50/50\n",
            "40000/40000 [==============================] - 11s 282us/step - loss: 0.1538 - acc: 0.9728 - val_loss: 3.2552 - val_acc: 0.6918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f753f334630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "-bwnsRTwRcaZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There is overfitting: the accuracy is much higher (97%) on the training data than on the validation data (69%)."
      ]
    },
    {
      "metadata": {
        "id": "rIifYKRSradN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Network with Dropout added, Architecture 2"
      ]
    },
    {
      "metadata": {
        "id": "pjBpyvX-rAyJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_dropout = Sequential()\n",
        "\n",
        "CNN_dropout.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "\n",
        "CNN_dropout.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "CNN_dropout.add(Dropout(1 - .9))\n",
        "\n",
        "CNN_dropout.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "CNN_dropout.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2) )\n",
        "CNN_dropout.add(Dropout(1 - .9))\n",
        "\n",
        "CNN_dropout.add(layers.Flatten())\n",
        "CNN_dropout.add(layers.Dense(512, activation='relu'))\n",
        "CNN_dropout.add(Dropout(1 - .9))\n",
        "\n",
        "CNN_dropout.add(layers.Dense(10, activation='softmax')) \n",
        "#CNN.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WKtdJnTCrjOR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1730
        },
        "outputId": "a745ef55-3a13-45a7-d604-f135d62879e6"
      },
      "cell_type": "code",
      "source": [
        "rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)  # default values: RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
        "CNN_dropout.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "CNN_dropout.fit(x=train_images, y=train_labels, batch_size=32, epochs=20, verbose=2, validation_split=0.2, shuffle=True)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            " - 12s - loss: 1.4741 - acc: 0.4752 - val_loss: 1.1561 - val_acc: 0.5927\n",
            "Epoch 2/50\n",
            " - 11s - loss: 1.0974 - acc: 0.6166 - val_loss: 1.0064 - val_acc: 0.6481\n",
            "Epoch 3/50\n",
            " - 11s - loss: 0.9479 - acc: 0.6729 - val_loss: 0.9147 - val_acc: 0.6875\n",
            "Epoch 4/50\n",
            " - 11s - loss: 0.8412 - acc: 0.7107 - val_loss: 0.9151 - val_acc: 0.6948\n",
            "Epoch 5/50\n",
            " - 11s - loss: 0.7555 - acc: 0.7396 - val_loss: 0.9307 - val_acc: 0.7013\n",
            "Epoch 6/50\n",
            " - 11s - loss: 0.6920 - acc: 0.7681 - val_loss: 0.9372 - val_acc: 0.6861\n",
            "Epoch 7/50\n",
            " - 11s - loss: 0.6390 - acc: 0.7849 - val_loss: 0.9116 - val_acc: 0.7148\n",
            "Epoch 8/50\n",
            " - 11s - loss: 0.5982 - acc: 0.7997 - val_loss: 0.9397 - val_acc: 0.7080\n",
            "Epoch 9/50\n",
            " - 11s - loss: 0.5690 - acc: 0.8103 - val_loss: 0.8930 - val_acc: 0.7197\n",
            "Epoch 10/50\n",
            " - 11s - loss: 0.5454 - acc: 0.8187 - val_loss: 0.9343 - val_acc: 0.7060\n",
            "Epoch 11/50\n",
            " - 11s - loss: 0.5315 - acc: 0.8261 - val_loss: 0.9405 - val_acc: 0.7181\n",
            "Epoch 12/50\n",
            " - 11s - loss: 0.5229 - acc: 0.8325 - val_loss: 1.0526 - val_acc: 0.7228\n",
            "Epoch 13/50\n",
            " - 11s - loss: 0.5156 - acc: 0.8356 - val_loss: 1.0671 - val_acc: 0.6831\n",
            "Epoch 14/50\n",
            " - 11s - loss: 0.5059 - acc: 0.8391 - val_loss: 1.0930 - val_acc: 0.7222\n",
            "Epoch 15/50\n",
            " - 11s - loss: 0.4991 - acc: 0.8403 - val_loss: 1.3024 - val_acc: 0.7006\n",
            "Epoch 16/50\n",
            " - 11s - loss: 0.4982 - acc: 0.8421 - val_loss: 1.1418 - val_acc: 0.7077\n",
            "Epoch 17/50\n",
            " - 11s - loss: 0.5081 - acc: 0.8418 - val_loss: 1.1639 - val_acc: 0.7145\n",
            "Epoch 18/50\n",
            " - 11s - loss: 0.5039 - acc: 0.8452 - val_loss: 1.1553 - val_acc: 0.6695\n",
            "Epoch 19/50\n",
            " - 11s - loss: 0.5009 - acc: 0.8453 - val_loss: 1.2288 - val_acc: 0.7187\n",
            "Epoch 20/50\n",
            " - 11s - loss: 0.4982 - acc: 0.8468 - val_loss: 1.1429 - val_acc: 0.7190\n",
            "Epoch 21/50\n",
            " - 11s - loss: 0.5033 - acc: 0.8449 - val_loss: 1.0978 - val_acc: 0.6839\n",
            "Epoch 22/50\n",
            " - 11s - loss: 0.4969 - acc: 0.8481 - val_loss: 1.1031 - val_acc: 0.6979\n",
            "Epoch 23/50\n",
            " - 11s - loss: 0.5012 - acc: 0.8484 - val_loss: 1.3242 - val_acc: 0.7220\n",
            "Epoch 24/50\n",
            " - 11s - loss: 0.5008 - acc: 0.8479 - val_loss: 1.1180 - val_acc: 0.6974\n",
            "Epoch 25/50\n",
            " - 11s - loss: 0.5022 - acc: 0.8491 - val_loss: 1.1694 - val_acc: 0.7048\n",
            "Epoch 26/50\n",
            " - 11s - loss: 0.5128 - acc: 0.8483 - val_loss: 1.2578 - val_acc: 0.6770\n",
            "Epoch 27/50\n",
            " - 11s - loss: 0.4986 - acc: 0.8497 - val_loss: 1.2147 - val_acc: 0.7029\n",
            "Epoch 28/50\n",
            " - 11s - loss: 0.5069 - acc: 0.8479 - val_loss: 1.2612 - val_acc: 0.7028\n",
            "Epoch 29/50\n",
            " - 11s - loss: 0.5234 - acc: 0.8427 - val_loss: 1.1652 - val_acc: 0.7007\n",
            "Epoch 30/50\n",
            " - 11s - loss: 0.5315 - acc: 0.8443 - val_loss: 1.2051 - val_acc: 0.7020\n",
            "Epoch 31/50\n",
            " - 11s - loss: 0.5411 - acc: 0.8443 - val_loss: 1.2092 - val_acc: 0.6794\n",
            "Epoch 32/50\n",
            " - 11s - loss: 0.5435 - acc: 0.8422 - val_loss: 1.1700 - val_acc: 0.6862\n",
            "Epoch 33/50\n",
            " - 11s - loss: 0.5565 - acc: 0.8399 - val_loss: 1.3436 - val_acc: 0.6577\n",
            "Epoch 34/50\n",
            " - 11s - loss: 0.5494 - acc: 0.8383 - val_loss: 1.2644 - val_acc: 0.7055\n",
            "Epoch 35/50\n",
            " - 11s - loss: 0.5417 - acc: 0.8424 - val_loss: 1.2128 - val_acc: 0.6646\n",
            "Epoch 36/50\n",
            " - 11s - loss: 0.5624 - acc: 0.8358 - val_loss: 1.4267 - val_acc: 0.7010\n",
            "Epoch 37/50\n",
            " - 11s - loss: 0.5695 - acc: 0.8339 - val_loss: 1.3948 - val_acc: 0.7008\n",
            "Epoch 38/50\n",
            " - 11s - loss: 0.5691 - acc: 0.8362 - val_loss: 1.2525 - val_acc: 0.6988\n",
            "Epoch 39/50\n",
            " - 10s - loss: 0.5618 - acc: 0.8388 - val_loss: 1.3188 - val_acc: 0.6392\n",
            "Epoch 40/50\n",
            " - 11s - loss: 0.5664 - acc: 0.8381 - val_loss: 1.2390 - val_acc: 0.6836\n",
            "Epoch 41/50\n",
            " - 10s - loss: 0.5783 - acc: 0.8346 - val_loss: 1.2077 - val_acc: 0.6880\n",
            "Epoch 42/50\n",
            " - 11s - loss: 0.5822 - acc: 0.8341 - val_loss: 1.2079 - val_acc: 0.7075\n",
            "Epoch 43/50\n",
            " - 10s - loss: 0.5895 - acc: 0.8309 - val_loss: 1.3258 - val_acc: 0.6780\n",
            "Epoch 44/50\n",
            " - 10s - loss: 0.5927 - acc: 0.8349 - val_loss: 1.2485 - val_acc: 0.6669\n",
            "Epoch 45/50\n",
            " - 10s - loss: 0.5870 - acc: 0.8308 - val_loss: 1.3516 - val_acc: 0.7195\n",
            "Epoch 46/50\n",
            " - 10s - loss: 0.5899 - acc: 0.8303 - val_loss: 1.1825 - val_acc: 0.6607\n",
            "Epoch 47/50\n",
            " - 10s - loss: 0.6080 - acc: 0.8305 - val_loss: 1.3346 - val_acc: 0.6548\n",
            "Epoch 48/50\n",
            " - 10s - loss: 0.6094 - acc: 0.8250 - val_loss: 1.3667 - val_acc: 0.6598\n",
            "Epoch 49/50\n",
            " - 10s - loss: 0.6148 - acc: 0.8272 - val_loss: 1.3687 - val_acc: 0.6983\n",
            "Epoch 50/50\n",
            " - 10s - loss: 0.6123 - acc: 0.8272 - val_loss: 1.3354 - val_acc: 0.6592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f753f334b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "6jXfotVMRqWy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There is still overfitting. Acc (83%) is much higher than val_acc (66%). Acc worsened compared to the first architecture, and so did the val_acc. So maybe dropout isn't the solution?"
      ]
    },
    {
      "metadata": {
        "id": "etXoYMUvZu4N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Network with additional densely connected layer (256) and conv2d (128), doubled # of filters at each step"
      ]
    },
    {
      "metadata": {
        "id": "VvdSVWGeaOVK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_expanded = Sequential()\n",
        "\n",
        "CNN_expanded.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "CNN_expanded.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "CNN_expanded.add(Dropout(1 - 0.95))\n",
        "\n",
        "CNN_expanded.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "CNN_expanded.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2) )\n",
        "CNN_expanded.add(Dropout(1 - 0.95))\n",
        "\n",
        "CNN_expanded.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
        "CNN_expanded.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2) )\n",
        "CNN_expanded.add(Dropout(1 - 0.95))\n",
        "\n",
        "CNN_expanded.add(layers.Flatten())\n",
        "CNN_expanded.add(layers.Dense(512, activation='relu'))\n",
        "CNN_expanded.add(Dropout(1 - 0.95))\n",
        "\n",
        "CNN_expanded.add(layers.Dense(256, activation='relu'))\n",
        "CNN_expanded.add(Dropout(1 - 0.95))\n",
        "\n",
        "CNN_expanded.add(layers.Dense(128, activation='relu'))\n",
        "\n",
        "CNN_expanded.add(layers.Dense(10, activation='softmax')) \n",
        "#CNN.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ON6q6R8paaTi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "9c4dd0b3-31dd-4b3c-a8ba-f7481a701306"
      },
      "cell_type": "code",
      "source": [
        "rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)  # default values: RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
        "CNN_expanded.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "CNN_expanded.fit(x=train_images, y=train_labels, batch_size=32, epochs=20, verbose=2, validation_split=0.2, shuffle=True)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            " - 25s - loss: 1.6340 - acc: 0.4077 - val_loss: 1.2870 - val_acc: 0.5361\n",
            "Epoch 2/20\n",
            " - 23s - loss: 1.2158 - acc: 0.5747 - val_loss: 1.1573 - val_acc: 0.5919\n",
            "Epoch 3/20\n",
            " - 23s - loss: 1.0403 - acc: 0.6438 - val_loss: 0.9968 - val_acc: 0.6697\n",
            "Epoch 4/20\n",
            " - 23s - loss: 0.9566 - acc: 0.6776 - val_loss: 1.0593 - val_acc: 0.6494\n",
            "Epoch 5/20\n",
            " - 23s - loss: 0.9159 - acc: 0.6970 - val_loss: 0.9529 - val_acc: 0.6851\n",
            "Epoch 6/20\n",
            " - 23s - loss: 0.9112 - acc: 0.7039 - val_loss: 0.9401 - val_acc: 0.6896\n",
            "Epoch 7/20\n",
            " - 23s - loss: 0.9109 - acc: 0.7072 - val_loss: 0.8655 - val_acc: 0.7260\n",
            "Epoch 8/20\n",
            " - 23s - loss: 0.9147 - acc: 0.7105 - val_loss: 1.0572 - val_acc: 0.6397\n",
            "Epoch 9/20\n",
            " - 23s - loss: 0.9025 - acc: 0.7160 - val_loss: 1.1887 - val_acc: 0.6373\n",
            "Epoch 10/20\n",
            " - 23s - loss: 0.9063 - acc: 0.7194 - val_loss: 0.9254 - val_acc: 0.7091\n",
            "Epoch 11/20\n",
            " - 23s - loss: 0.9135 - acc: 0.7181 - val_loss: 0.9058 - val_acc: 0.7175\n",
            "Epoch 12/20\n",
            " - 23s - loss: 0.9168 - acc: 0.7191 - val_loss: 1.2229 - val_acc: 0.6820\n",
            "Epoch 13/20\n",
            " - 23s - loss: 0.9238 - acc: 0.7151 - val_loss: 0.9181 - val_acc: 0.7001\n",
            "Epoch 14/20\n",
            " - 23s - loss: 0.9212 - acc: 0.7200 - val_loss: 1.0046 - val_acc: 0.6609\n",
            "Epoch 15/20\n",
            " - 23s - loss: 0.9244 - acc: 0.7219 - val_loss: 0.9694 - val_acc: 0.6987\n",
            "Epoch 16/20\n",
            " - 23s - loss: 0.9135 - acc: 0.7223 - val_loss: 0.9805 - val_acc: 0.7047\n",
            "Epoch 17/20\n",
            " - 23s - loss: 0.9184 - acc: 0.7235 - val_loss: 1.0133 - val_acc: 0.6908\n",
            "Epoch 18/20\n",
            " - 23s - loss: 0.9303 - acc: 0.7258 - val_loss: 0.9677 - val_acc: 0.7010\n",
            "Epoch 19/20\n",
            " - 23s - loss: 0.9270 - acc: 0.7225 - val_loss: 0.9102 - val_acc: 0.7102\n",
            "Epoch 20/20\n",
            " - 23s - loss: 0.9485 - acc: 0.7287 - val_loss: 0.9817 - val_acc: 0.7237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f753a18b6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "YgJbTCmLoQZM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Network with augmented images, Architecture 4"
      ]
    },
    {
      "metadata": {
        "id": "t4jDPrqNIyqO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "aug_train = train_images[0:40000]\n",
        "aug_validate = train_images[40000:50000]\n",
        "\n",
        "#datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.15, zoom_range=0.1, channel_shift_range=10., horizontal_flip=True)\n",
        "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1, channel_shift_range=0.1, horizontal_flip=True)\n",
        "\n",
        "datagen.fit(aug_train)\n",
        "#test = [0, 1, 2, 3]\n",
        "#print(test[0:2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8hNpc4QnJnkG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CNN_augmented = Sequential()\n",
        "\n",
        "CNN_augmented.add(layers.Conv2D(filters=32, kernel_size=(5, 5), activation='relu', input_shape=(32, 32, 3)))\n",
        "\n",
        "CNN_augmented.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "#CNN_augmented.add(Dropout(1 - .9))\n",
        "\n",
        "CNN_augmented.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "CNN_augmented.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2) )\n",
        "#CNN_augmented.add(Dropout(1 - .9))\n",
        "\n",
        "CNN_augmented.add(layers.Flatten())\n",
        "CNN_augmented.add(layers.Dense(512, activation='relu'))\n",
        "#CNN_augmented.add(Dropout(1 - .9))\n",
        "\n",
        "CNN_augmented.add(layers.Dense(10, activation='softmax')) \n",
        "#CNN.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aFYuW6VMJn4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "c44a7387-0060-4af6-be2a-2abfe03d70eb"
      },
      "cell_type": "code",
      "source": [
        "rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)  # default values: RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
        "CNN_augmented.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#CNN_augmented.fit(x=train_images_bw, y=train_labels, batch_size=32, epochs=20, verbose=2, validation_split=0.2, shuffle=True)\n",
        "\n",
        "CNN_augmented.fit_generator(datagen.flow(train_images[0:40000], train_labels[0:40000], batch_size=32),\n",
        "                    steps_per_epoch=ceil(40000 / 32), epochs=20, verbose=1, validation_data=(train_images[40000:50000], train_labels[40000:50000]))#, validation_split=0.2, shuffle=True)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1250/1250 [==============================] - 31s 25ms/step - loss: 1.6156 - acc: 0.4234 - val_loss: 1.2398 - val_acc: 0.5628\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 1.2868 - acc: 0.5462 - val_loss: 1.2377 - val_acc: 0.5745\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.1690 - acc: 0.5934 - val_loss: 1.0451 - val_acc: 0.6382\n",
            "Epoch 4/20\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 1.1075 - acc: 0.6180 - val_loss: 0.9617 - val_acc: 0.6671\n",
            "Epoch 5/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.0752 - acc: 0.6318 - val_loss: 0.9626 - val_acc: 0.6763\n",
            "Epoch 6/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.0430 - acc: 0.6419 - val_loss: 0.9489 - val_acc: 0.6821\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.0300 - acc: 0.6489 - val_loss: 0.9968 - val_acc: 0.6738\n",
            "Epoch 8/20\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.0225 - acc: 0.6537 - val_loss: 1.2902 - val_acc: 0.6157\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.0123 - acc: 0.6580 - val_loss: 1.0015 - val_acc: 0.6686\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.0022 - acc: 0.6610 - val_loss: 0.9703 - val_acc: 0.6809\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9980 - acc: 0.6653 - val_loss: 0.8858 - val_acc: 0.7104\n",
            "Epoch 12/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9973 - acc: 0.6648 - val_loss: 0.8994 - val_acc: 0.6958\n",
            "Epoch 13/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9923 - acc: 0.6643 - val_loss: 0.9441 - val_acc: 0.6908\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9960 - acc: 0.6643 - val_loss: 0.9618 - val_acc: 0.6764\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9857 - acc: 0.6712 - val_loss: 1.0355 - val_acc: 0.6759\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9866 - acc: 0.6751 - val_loss: 0.9523 - val_acc: 0.7010\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9895 - acc: 0.6732 - val_loss: 0.9790 - val_acc: 0.6796\n",
            "Epoch 18/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 0.9928 - acc: 0.6696 - val_loss: 0.9215 - val_acc: 0.7030\n",
            "Epoch 19/20\n",
            "1250/1250 [==============================] - 29s 24ms/step - loss: 0.9873 - acc: 0.6747 - val_loss: 1.0055 - val_acc: 0.6743\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9917 - acc: 0.6700 - val_loss: 0.9009 - val_acc: 0.7118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f753ac675f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "KVtwCiz4X_QE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### \"Train this final architecture on the data from the training set and validation set and evaluate its performance on the test set.\""
      ]
    },
    {
      "metadata": {
        "id": "Xe8mn1CiX-b1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "outputId": "720bd037-23ee-4ffc-d6f8-84814b984c42"
      },
      "cell_type": "code",
      "source": [
        "CNN_augmented.fit(x=train_images, y=train_labels, batch_size=32, epochs=50, verbose=1, shuffle=True)\n",
        "score = CNN_augmented.evaluate(test_images, test_labels, batch_size=32)\n",
        "print()\n",
        "print(str(score[1] * 100) + \"% accuracy\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 1.0897 - acc: 0.6483\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 1.0788 - acc: 0.6529\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 1.0762 - acc: 0.6511\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 1.0941 - acc: 0.6494\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 1.0893 - acc: 0.6514\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 1.0944 - acc: 0.6466\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 1.0828 - acc: 0.6496\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 1.0927 - acc: 0.6495\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 1.0769 - acc: 0.6498\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 1.0826 - acc: 0.6531\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 1.0770 - acc: 0.6508\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 1.0789 - acc: 0.6492\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 15s 302us/step - loss: 1.0796 - acc: 0.6494\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 1.0818 - acc: 0.6505\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 1.0966 - acc: 0.6497\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 15s 302us/step - loss: 1.0808 - acc: 0.6518\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 1.0665 - acc: 0.6565\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 1.0808 - acc: 0.6520\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 1.0814 - acc: 0.6515\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 15s 302us/step - loss: 1.0690 - acc: 0.6557\n",
            "10000/10000 [==============================] - 1s 102us/step\n",
            "\n",
            "67.82000000000001% accuracy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iAfq3uvhYyC0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reevaluate your best architecture using k-fold validation with k=5, that is, the size of the validation fold is 20%. Does the accuracy/loss obtain by k-fold validation differ from the accuracy/loss obtain by simple hold-out validation."
      ]
    },
    {
      "metadata": {
        "id": "JLR6BR7pUfQ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23f49f28-bbd2-4fdc-d501-e2aec37268a4"
      },
      "cell_type": "code",
      "source": [
        "test = [0,1,2,3,4,5,6,7,8,9]\n",
        "print(test[0:7]+test[8:10])\n",
        "\n",
        "#train_images[0:10000]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 8, 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JUCPDPOIGsZw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3377
        },
        "outputId": "1d9277d5-54e7-46c5-a06f-a121ccd1c562"
      },
      "cell_type": "code",
      "source": [
        "# Folds (validation sets):\n",
        "fold1 = train_images[0:10000]\n",
        "fold2 = train_images[10000:20000]\n",
        "fold3 = train_images[20000:30000]\n",
        "fold4 = train_images[30000:40000]\n",
        "fold5 = train_images[40000:50000]\n",
        "folds = [fold1,fold2,fold3,fold4,fold5] \n",
        "\n",
        "fold_label_set1 = train_labels[0:10000]\n",
        "fold_label_set2 = train_labels[10000:20000]\n",
        "fold_label_set3 = train_labels[20000:30000]\n",
        "fold_label_set4 = train_labels[30000:40000]\n",
        "fold_label_set5 = train_labels[40000:50000]\n",
        "fold_labels = [fold_label_set1,fold_label_set2,fold_label_set3,fold_label_set4,fold_label_set5] \n",
        "\n",
        "# Train sets\n",
        "train1 = train_images[10000:50000]\n",
        "train2 = np.concatenate((train_images[0:10000], train_images[20000:50000]))\n",
        "train3 = np.concatenate((train_images[0:20000], train_images[30000:50000]))\n",
        "train4 = np.concatenate((train_images[0:30000], train_images[40000:50000]))\n",
        "train5 = train_images[0:40000]\n",
        "train_sets = [train1,train2,train3,train4,train5]\n",
        "\n",
        "trainlabel1 = train_labels[10000:50000]\n",
        "trainlabel2 = np.concatenate((train_labels[0:10000], train_labels[20000:50000]))\n",
        "trainlabel3 = np.concatenate((train_labels[0:20000], train_labels[30000:50000]))\n",
        "trainlabel4 = np.concatenate((train_labels[0:30000], train_labels[40000:50000]))\n",
        "trainlabel5 = train_labels[0:40000]\n",
        "train_label_sets = [trainlabel1,trainlabel2,trainlabel3,trainlabel4,trainlabel5]\n",
        "\n",
        "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.1, channel_shift_range=0.1, horizontal_flip=True)\n",
        "datagen.fit(train_images[0:40000])\n",
        "\n",
        "CNN_augmented = Sequential()\n",
        "CNN_augmented.add(layers.Conv2D(filters=32, kernel_size=(5, 5), activation='relu', input_shape=(32, 32, 3)))\n",
        "CNN_augmented.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "CNN_augmented.add(Dropout(1 - .9))\n",
        "CNN_augmented.add(layers.Conv2D(64, (5, 5), activation='relu'))\n",
        "CNN_augmented.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2) )\n",
        "CNN_augmented.add(Dropout(1 - .9))\n",
        "CNN_augmented.add(layers.Flatten())\n",
        "CNN_augmented.add(layers.Dense(512, activation='relu'))\n",
        "CNN_augmented.add(Dropout(1 - .9))\n",
        "CNN_augmented.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "rmsprop = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
        "CNN_augmented.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "for fold,fold_label_set,train_set,train_label_set in zip(folds,fold_labels,train_sets,train_label_sets):\n",
        "    CNN_augmented.fit_generator(datagen.flow(train_set, train_label_set, batch_size=32), steps_per_epoch=ceil(40000 / 32), epochs=20, verbose=1, validation_data=(fold, fold_label_set))\n",
        "    print()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1250/1250 [==============================] - 29s 24ms/step - loss: 1.6735 - acc: 0.3938 - val_loss: 1.3792 - val_acc: 0.5002\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 1.3950 - acc: 0.5076 - val_loss: 1.1887 - val_acc: 0.5799\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 1.2883 - acc: 0.5524 - val_loss: 1.0739 - val_acc: 0.6296\n",
            "Epoch 4/20\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 1.2326 - acc: 0.5701 - val_loss: 1.0041 - val_acc: 0.6580\n",
            "Epoch 5/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.2096 - acc: 0.5837 - val_loss: 1.0355 - val_acc: 0.6439\n",
            "Epoch 6/20\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 1.1942 - acc: 0.5938 - val_loss: 1.1940 - val_acc: 0.6095\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 1.1860 - acc: 0.5983 - val_loss: 1.5090 - val_acc: 0.4807\n",
            "Epoch 8/20\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 1.1913 - acc: 0.5976 - val_loss: 1.2404 - val_acc: 0.6192\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 1.2066 - acc: 0.5944 - val_loss: 1.0175 - val_acc: 0.6612\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.1935 - acc: 0.6000 - val_loss: 1.1218 - val_acc: 0.6101\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.1988 - acc: 0.5967 - val_loss: 0.9876 - val_acc: 0.6630\n",
            "Epoch 12/20\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 1.2072 - acc: 0.5948 - val_loss: 0.9557 - val_acc: 0.6894\n",
            "Epoch 13/20\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 1.2026 - acc: 0.6010 - val_loss: 0.9818 - val_acc: 0.6738\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 1.2087 - acc: 0.5975 - val_loss: 1.0981 - val_acc: 0.6440\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 1.2187 - acc: 0.5993 - val_loss: 1.0927 - val_acc: 0.6312\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.2160 - acc: 0.5967 - val_loss: 0.9588 - val_acc: 0.6775\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2182 - acc: 0.5992 - val_loss: 1.0434 - val_acc: 0.6494\n",
            "Epoch 18/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2339 - acc: 0.5915 - val_loss: 1.0627 - val_acc: 0.6445\n",
            "Epoch 19/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2260 - acc: 0.5950 - val_loss: 1.2813 - val_acc: 0.5679\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2270 - acc: 0.5935 - val_loss: 1.1545 - val_acc: 0.6393\n",
            "Epoch 1/20\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 1.2569 - acc: 0.5820 - val_loss: 0.9561 - val_acc: 0.6845\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.2374 - acc: 0.5897 - val_loss: 1.0698 - val_acc: 0.6397\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2485 - acc: 0.5877 - val_loss: 0.9734 - val_acc: 0.6700\n",
            "Epoch 4/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2677 - acc: 0.5787 - val_loss: 1.0909 - val_acc: 0.6280\n",
            "Epoch 5/20\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 1.2612 - acc: 0.5774 - val_loss: 1.1725 - val_acc: 0.6096\n",
            "Epoch 6/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.2626 - acc: 0.5821 - val_loss: 1.0098 - val_acc: 0.6617\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2760 - acc: 0.5772 - val_loss: 1.0780 - val_acc: 0.6424\n",
            "Epoch 8/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2682 - acc: 0.5773 - val_loss: 1.0849 - val_acc: 0.6309\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2719 - acc: 0.5799 - val_loss: 0.9632 - val_acc: 0.6781\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2727 - acc: 0.5796 - val_loss: 1.1267 - val_acc: 0.6162\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2818 - acc: 0.5765 - val_loss: 1.0631 - val_acc: 0.6424\n",
            "Epoch 12/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2878 - acc: 0.5743 - val_loss: 1.0306 - val_acc: 0.6591\n",
            "Epoch 13/20\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.2889 - acc: 0.5759 - val_loss: 1.0639 - val_acc: 0.6442\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2863 - acc: 0.5762 - val_loss: 1.0509 - val_acc: 0.6424\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2896 - acc: 0.5697 - val_loss: 1.0583 - val_acc: 0.6498\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3011 - acc: 0.5749 - val_loss: 1.1086 - val_acc: 0.6209\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.3029 - acc: 0.5700 - val_loss: 0.9913 - val_acc: 0.6729\n",
            "Epoch 18/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3072 - acc: 0.5694 - val_loss: 1.0175 - val_acc: 0.6741\n",
            "Epoch 19/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3058 - acc: 0.5707 - val_loss: 1.2909 - val_acc: 0.5601\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2978 - acc: 0.5680 - val_loss: 1.0730 - val_acc: 0.6389\n",
            "Epoch 1/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3243 - acc: 0.5588 - val_loss: 1.0936 - val_acc: 0.6433\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3258 - acc: 0.5568 - val_loss: 1.3039 - val_acc: 0.5513\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3271 - acc: 0.5620 - val_loss: 1.0112 - val_acc: 0.6652\n",
            "Epoch 4/20\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.3275 - acc: 0.5609 - val_loss: 1.0667 - val_acc: 0.6468\n",
            "Epoch 5/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3229 - acc: 0.5621 - val_loss: 1.2771 - val_acc: 0.5827\n",
            "Epoch 6/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3455 - acc: 0.5527 - val_loss: 1.1495 - val_acc: 0.6011\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3272 - acc: 0.5580 - val_loss: 1.2515 - val_acc: 0.5544\n",
            "Epoch 8/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.3398 - acc: 0.5531 - val_loss: 1.1180 - val_acc: 0.6227\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3449 - acc: 0.5582 - val_loss: 1.0755 - val_acc: 0.6619\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3353 - acc: 0.5579 - val_loss: 1.2424 - val_acc: 0.5963\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3329 - acc: 0.5560 - val_loss: 1.1166 - val_acc: 0.6370\n",
            "Epoch 12/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3323 - acc: 0.5629 - val_loss: 1.0403 - val_acc: 0.6619\n",
            "Epoch 13/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3239 - acc: 0.5589 - val_loss: 1.1586 - val_acc: 0.5933\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3221 - acc: 0.5584 - val_loss: 1.1533 - val_acc: 0.6234\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.3310 - acc: 0.5579 - val_loss: 1.0331 - val_acc: 0.6646\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3146 - acc: 0.5625 - val_loss: 1.2219 - val_acc: 0.6021\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3216 - acc: 0.5599 - val_loss: 1.0177 - val_acc: 0.6683\n",
            "Epoch 18/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3196 - acc: 0.5634 - val_loss: 1.0055 - val_acc: 0.6644\n",
            "Epoch 19/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.3159 - acc: 0.5621 - val_loss: 1.0441 - val_acc: 0.6513\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3205 - acc: 0.5602 - val_loss: 1.2307 - val_acc: 0.5510\n",
            "Epoch 1/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3112 - acc: 0.5673 - val_loss: 1.2482 - val_acc: 0.5783\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3146 - acc: 0.5634 - val_loss: 1.1128 - val_acc: 0.6179\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.2986 - acc: 0.5661 - val_loss: 1.0667 - val_acc: 0.6352\n",
            "Epoch 4/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3126 - acc: 0.5637 - val_loss: 1.0775 - val_acc: 0.6320\n",
            "Epoch 5/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3126 - acc: 0.5692 - val_loss: 1.1455 - val_acc: 0.6252\n",
            "Epoch 6/20\n",
            "1250/1250 [==============================] - 29s 24ms/step - loss: 1.3103 - acc: 0.5670 - val_loss: 1.0862 - val_acc: 0.6476\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3020 - acc: 0.5666 - val_loss: 1.0530 - val_acc: 0.6475\n",
            "Epoch 8/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3090 - acc: 0.5666 - val_loss: 1.0936 - val_acc: 0.6384\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3181 - acc: 0.5680 - val_loss: 1.2149 - val_acc: 0.6255\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.3130 - acc: 0.5636 - val_loss: 1.3921 - val_acc: 0.4895\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3153 - acc: 0.5669 - val_loss: 1.0195 - val_acc: 0.6585\n",
            "Epoch 12/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3170 - acc: 0.5669 - val_loss: 1.0276 - val_acc: 0.6613\n",
            "Epoch 13/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3175 - acc: 0.5628 - val_loss: 1.0442 - val_acc: 0.6566\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3123 - acc: 0.5653 - val_loss: 1.1029 - val_acc: 0.6223\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3120 - acc: 0.5637 - val_loss: 1.1740 - val_acc: 0.5975\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3244 - acc: 0.5623 - val_loss: 1.0294 - val_acc: 0.6634\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.3060 - acc: 0.5674 - val_loss: 1.0787 - val_acc: 0.6489\n",
            "Epoch 18/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3042 - acc: 0.5672 - val_loss: 1.2521 - val_acc: 0.5946\n",
            "Epoch 19/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3177 - acc: 0.5631 - val_loss: 1.0036 - val_acc: 0.6677\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3237 - acc: 0.5608 - val_loss: 1.1622 - val_acc: 0.6273\n",
            "Epoch 1/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.3136 - acc: 0.5629 - val_loss: 1.2191 - val_acc: 0.5947\n",
            "Epoch 2/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3309 - acc: 0.5606 - val_loss: 1.1051 - val_acc: 0.6268\n",
            "Epoch 3/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3161 - acc: 0.5639 - val_loss: 2.2704 - val_acc: 0.5703\n",
            "Epoch 4/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3280 - acc: 0.5655 - val_loss: 1.1519 - val_acc: 0.6189\n",
            "Epoch 5/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3042 - acc: 0.5692 - val_loss: 1.0798 - val_acc: 0.6496\n",
            "Epoch 6/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3381 - acc: 0.5558 - val_loss: 1.0114 - val_acc: 0.6732\n",
            "Epoch 7/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3206 - acc: 0.5656 - val_loss: 1.6058 - val_acc: 0.6045\n",
            "Epoch 8/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.3352 - acc: 0.5599 - val_loss: 1.0629 - val_acc: 0.6492\n",
            "Epoch 9/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3356 - acc: 0.5630 - val_loss: 1.1600 - val_acc: 0.6132\n",
            "Epoch 10/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3334 - acc: 0.5607 - val_loss: 1.4269 - val_acc: 0.4954\n",
            "Epoch 11/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3108 - acc: 0.5692 - val_loss: 1.1649 - val_acc: 0.6074\n",
            "Epoch 12/20\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 1.3443 - acc: 0.5601 - val_loss: 1.2437 - val_acc: 0.6217\n",
            "Epoch 13/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3373 - acc: 0.5606 - val_loss: 1.2285 - val_acc: 0.5913\n",
            "Epoch 14/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3276 - acc: 0.5650 - val_loss: 1.0041 - val_acc: 0.6712\n",
            "Epoch 15/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3201 - acc: 0.5655 - val_loss: 1.0162 - val_acc: 0.6656\n",
            "Epoch 16/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3137 - acc: 0.5635 - val_loss: 1.0205 - val_acc: 0.6675\n",
            "Epoch 17/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3140 - acc: 0.5655 - val_loss: 1.1516 - val_acc: 0.6237\n",
            "Epoch 18/20\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 1.3322 - acc: 0.5619 - val_loss: 1.0707 - val_acc: 0.6489\n",
            "Epoch 19/20\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 1.3397 - acc: 0.5609 - val_loss: 1.1278 - val_acc: 0.6401\n",
            "Epoch 20/20\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 1.3295 - acc: 0.5614 - val_loss: 1.1173 - val_acc: 0.6332\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}